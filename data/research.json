[
    {
        "name": "3D Ken Burns",
        "description": "A reference implementation of 3D Ken Burns Effect from a Single Image using PyTorch - given a single input image, it animates this still image with a virtual camera scan and zoom subject to motion parallax",
        "author": [
            [
                "Manuel Romero",
                "https://mrm8488.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1909.05483"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=WrajxHHfRBA"
            ],
            [
                "git",
                "https://github.com/sniklaus/3d-ken-burns",
                1427
            ]
        ],
        "tir_url": "{tir_base_url}/github/mrm8488/shared_colab_notebooks/blob/master/3D_Ken_Burns.ipynb/",
        "update": 1592066293
    },
    {
        "name": "Learning to Paint",
        "description": "Learning to Paint With Model-based Deep Reinforcement Learning",
        "author": [
            [
                "Manuel Romero",
                "https://mrm8488.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1903.04411"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=YmOgKZ5oipk"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/reinforcementlearning/comments/b5lpfl/learning_to_paint_with_modelbased_deep/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/mrm8488/shared_colab_notebooks/blob/master/custom_learningtopaint.ipynb/",
        "update": 1675240348
    },
    {
        "name": "WikiArt (stylegan2)",
        "description": "Generation of paintings of different styles and genres",
        "author": [
            [
                "Doron Adler",
                "https://linktr.ee/Norod78"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1912.04958"
            ]
        ],
        "tir_url": "{tir_base_url}/github/Norod/my-colab-experiments/blob/master/WikiArt_Example_Generation_By_Peter_Baylies.ipynb/",
        "update": 1580103743
    },
    {
        "name": "WikiArt (stylegan2-ada)",
        "description": "Generation of paintings of different styles and genres",
        "author": [
            [
                "Doron Adler",
                "https://linktr.ee/Norod78"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2006.06676"
            ]
        ],
        "tir_url": "{tir_base_url}/github/Norod/my-colab-experiments/blob/master/WikiArt_ADA_Example_Generation.ipynb/",
        "update": 1607411003
    },
    {
        "name": "Customizing a Transformer Encoder",
        "description": "We will learn how to customize the encoder to employ new network architectures",
        "author": [
            [
                "Chen Chen",
                "https://github.com/chenGitHuber"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03762"
            ],
            [
                "git",
                "https://github.com/tensorflow/models/tree/master/official/nlp/modeling",
                75872
            ],
            [
                "git",
                "https://github.com/tensorflow/models/blob/master/official/nlp/modeling/networks/encoder_scaffold.py"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tensorflow/models/blob/master/official/colab/nlp/customize_encoder.ipynb/",
        "update": 1655916395
    },
    {
        "name": "Fine-tuning a BERT",
        "description": "We will work through fine-tuning a BERT model using the tensorflow-models PIP package",
        "author": [
            [
                "Chen Chen",
                "https://github.com/chenGitHuber"
            ],
            [
                "Claire Yao",
                "https://github.com/claireyao-fen"
            ]
        ],
        "links": [
            [
                "tf",
                "https://tensorflow.org/hub"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb/",
        "update": 1621892037
    },
    {
        "name": "First Order Motion Model for Image Animation",
        "description": "Transferring facial movements from video to image",
        "author": [
            [
                "Aliaksandr Siarohin",
                "https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/"
            ]
        ],
        "links": [
            [
                "neurips",
                "https://papers.nips.cc/paper/2019/hash/31c0b36aef265d9221af80872ceb62f9-Abstract.html"
            ],
            [
                "git",
                "https://github.com/AliaksandrSiarohin/first-order-model",
                13486
            ],
            [
                "project",
                "https://aliaksandrsiarohin.github.io/first-order-model-website/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=u-0cQ-grXBQ"
            ]
        ],
        "tir_url": "{tir_base_url}/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb/",
        "update": 1670496979
    },
    {
        "name": "Motion Supervised co-part Segmentation",
        "description": "A self-supervised deep learning method for co-part segmentation",
        "author": [
            [
                "Aliaksandr Siarohin",
                "https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/"
            ],
            [
                "Subhankar Roy",
                "https://github.com/roysubhankar"
            ]
        ],
        "links": [
            [
                "arxiv",
                "http://arxiv.org/abs/2004.03234"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=RJ4Nj1wV5iA"
            ],
            [
                "git",
                "https://github.com/AliaksandrSiarohin/motion-cosegmentation",
                614
            ],
            [
                "git",
                "https://github.com/AliaksandrSiarohin/video-preprocessing"
            ]
        ],
        "tir_url": "{tir_base_url}/github/AliaksandrSiarohin/motion-cosegmentation/blob/master/part_swap.ipynb/",
        "update": 1586278532
    },
    {
        "name": "Motion Representations for Articulated Animation",
        "description": "Novel motion representations for animating articulated objects consisting of distinct parts",
        "author": [
            [
                "Aliaksandr Siarohin",
                "https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/"
            ],
            [
                "Oliver Woodford",
                "https://ojwoodford.github.io/"
            ],
            [
                "Jian Ren",
                "https://alanspike.github.io/"
            ],
            [
                "Menglei Chai",
                "https://mlchai.com/"
            ],
            [
                "Sergey Tulyakov",
                "http://www.stulyakov.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://snap-research.github.io/articulated-animation/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.11280"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=gpBYN8t8_yY"
            ],
            [
                "git",
                "https://github.com/snap-research/articulated-animation",
                986
            ]
        ],
        "tir_url": "{tir_base_url}/github/AliaksandrSiarohin/articulated-animation/blob/master/demo.ipynb/",
        "update": 1619713260
    },
    {
        "name": "DeOldify (video)",
        "description": "Colorize your own videos!",
        "author": [
            [
                "Jason Antic",
                "https://github.com/jantic"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08500"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/Nickelodeons/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/silentmoviegifs/"
            ],
            [
                "youtube",
                "http://www.youtube.com/watch?v=l3UXXid04Ys"
            ],
            [
                "youtube",
                "http://www.youtube.com/watch?v=EXn-n2iqEjI"
            ],
            [
                "model",
                "https://data.deepai.org/deoldify/ColorizeVideo_gen.pth"
            ],
            [
                "medium",
                "https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42"
            ]
        ],
        "tir_url": "{tir_base_url}/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb/",
        "update": 1663572869
    },
    {
        "name": "DeOldify (photo)",
        "description": "Colorize your own photos!",
        "author": [
            [
                "Jason Antic",
                "https://github.com/jantic"
            ],
            [
                "Matt Robinson",
                "https://github.com/mc-robinson"
            ],
            [
                "María Benavente",
                "https://github.com/mariabg"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08500"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/TheWayWeWere/"
            ],
            [
                "model",
                "https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth"
            ]
        ],
        "tir_url": "{tir_base_url}/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb/",
        "update": 1663572869
    },
    {
        "name": "Faceswap-GAN",
        "description": "A minimum demo for faceswap-GAN v2.2",
        "author": [
            [
                "shaoanlu",
                "https://shaoanlu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/shaoanlu/faceswap-GAN",
                3250
            ]
        ],
        "tir_url": "{tir_base_url}/github/shaoanlu/faceswap-GAN/blob/master/colab_demo/faceswap-GAN_colab_demo.ipynb/",
        "update": 1599883870
    },
    {
        "name": "DFL-Colab",
        "description": "This project provides you IPython Notebook to use DeepFaceLab",
        "author": [
            [
                "chervonij",
                "https://github.com/chervonij"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05535"
            ],
            [
                "youtube",
                "https://www.youtube.com/channel/UCTKBl8kB6DJ_qLnk1NGDGbQ"
            ],
            [
                "guide",
                "https://mrdeepfakes.com/forums/thread-guide-deepfacelab-google-colab-tutorial"
            ],
            [
                "git",
                "https://github.com/iperov/DeepFaceLab",
                39961
            ]
        ],
        "tir_url": "{tir_base_url}/github/chervonij/DFL-Colab/blob/master/DFL_Colab.ipynb/",
        "update": 1682825899
    },
    {
        "name": "T5",
        "description": "Text-To-Text Transfer Transformer",
        "author": [
            [
                "Colin Raffel",
                "https://colinraffel.com/"
            ],
            [
                "Noam Shazeer",
                "https://scholar.google.com/citations?user=wsGvgA8AAAAJ"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Katherine Lee",
                "https://github.com/katelee168"
            ],
            [
                "Sharan Narang",
                "https://github.com/sharannarang"
            ],
            [
                "Michael Matena",
                "https://scholar.google.com/citations?user=rN_9vroAAAAJ"
            ],
            [
                "Yanqi Zhou",
                "https://zhouyanqi.github.io"
            ],
            [
                "Wei Li",
                "https://research.google/people/106528/"
            ],
            [
                "Peter J. Liu",
                "https://scholar.google.com/citations?user=1EPxhywAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-research/text-to-text-transfer-transformer",
                5213
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.10683"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets"
            ],
            [
                "git",
                "https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow/transformer"
            ]
        ],
        "tir_url": "{tir_base_url}/github/google-research/text-to-text-transfer-transformer/blob/main/notebooks/t5-trivia.ipynb/",
        "update": 1652294461
    },
    {
        "name": "OWL-ViT",
        "description": "Simple Open-Vocabulary Object Detection with Vision Transformers",
        "author": [
            [
                "Matthias Minderer",
                "http://matthias.minderer.net/"
            ],
            [
                "Alexey Gritsenko",
                "https://github.com/AlexeyG"
            ],
            [
                "Austin Stone",
                "https://github.com/AustinCStone"
            ],
            [
                "Maxim Neumann",
                "https://github.com/maximneumann"
            ],
            [
                "Dirk Weissenborn",
                "https://github.com/dirkweissenborn"
            ],
            [
                "Alexey Dosovitskiy",
                "https://scholar.google.com/citations?user=FXNJRDoAAAAJ"
            ],
            [
                "Aravindh Mahendran",
                "https://github.com/aravindhm"
            ],
            [
                "Anurag Arnab",
                "https://github.com/anuragarnab"
            ],
            [
                "Mostafa Dehghani",
                "https://mostafadehghani.com/"
            ],
            [
                "Zhuoran Shen",
                "https://cmsflash.github.io/"
            ],
            [
                "Xiao Wang",
                "https://scholar.google.com/citations?user=ukyXqzMAAAAJ"
            ],
            [
                "Xiaohua Zhai",
                "https://github.com/xiaohuazhai"
            ],
            [
                "Thomas Kipf",
                "https://tkipf.github.io/"
            ],
            [
                "Neil Houlsby",
                "https://neilhoulsby.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2205.06230"
            ],
            [
                "huggingface",
                "https://huggingface.co/docs/transformers/model_doc/owlvit"
            ],
            [
                "git",
                "https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit",
                2207
            ]
        ],
        "tir_url": "{tir_base_url}/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb/",
        "update": 1675863392
    },
    {
        "name": "StylEx",
        "description": "Training a GAN to explain a classifier in StyleSpace",
        "author": [
            [
                "Oran Lang",
                "https://research.google/people/105975/"
            ],
            [
                "Yossi Gandelsman",
                "https://yossigandelsman.github.io/"
            ],
            [
                "Michal Yarom",
                "https://scholar.google.com/citations?user=GMVxiYgAAAAJ"
            ],
            [
                "Yoav Wald",
                "https://scholar.google.com/citations?user=hh5nOn4AAAAJ"
            ],
            [
                "Gal Elidan",
                "https://research.google/people/105719/"
            ],
            [
                "Avinatan Hassidim",
                "https://research.google/people/105831/"
            ],
            [
                "William Freeman",
                "https://billf.mit.edu/"
            ],
            [
                "Phillip Isola",
                "http://web.mit.edu/phillipi/"
            ],
            [
                "Amir Globerso",
                "https://cs3801.wixsite.com/amirgloberson"
            ],
            [
                "Michal Irani",
                "http://www.weizmann.ac.il/math/irani/"
            ],
            [
                "Inbar Mosseri",
                "https://research.google/people/InbarMosseri/"
            ]
        ],
        "links": [
            [
                "project",
                "https://explaining-in-style.github.io/"
            ],
            [
                "git",
                "https://github.com/google/explaining-in-style",
                206
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.13369"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2022/01/introducing-stylex-new-approach-for.html"
            ],
            [
                "youtube",
                "https://youtu.be/wLk2eBdXH4M"
            ],
            [
                "supplementary",
                "https://explaining-in-style.github.io/supmat.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1906.10112"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.12799"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.04958"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.01711"
            ]
        ],
        "tir_url": "{tir_base_url}/github/google/explaining-in-style/blob/main/Explaining_in_Style_AttFind.ipynb/",
        "update": 1629907166
    },
    {
        "name": "IC-GAN",
        "description": "Instance-Conditioned GAN",
        "author": [
            [
                "Arantxa Casanova",
                "https://github.com/ArantxaCasanova"
            ],
            [
                "Marlène Careil",
                "https://www.linkedin.com/in/marl%C3%A8ne-careil-901804155"
            ],
            [
                "Jakob Verbeek",
                "http://thoth.inrialpes.fr/~verbeek/"
            ],
            [
                "Michał Drożdżal",
                "https://scholar.google.com/citations?user=XK_ktwQAAAAJ"
            ],
            [
                "Adriana Romero-Soriano",
                "https://sites.google.com/site/adriromsor"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/ic_gan",
                521
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.05070"
            ],
            [
                "git",
                "https://github.com/facebookresearch/faiss"
            ],
            [
                "git",
                "https://github.com/ajbrock/BigGAN-PyTorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada-pytorch"
            ],
            [
                "git",
                "https://github.com/bioinf-jku/TTUR"
            ],
            [
                "git",
                "https://github.com/mit-han-lab/data-efficient-gans"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/instance-conditioned-gans/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/facebookresearch/ic_gan/blob/master/inference/icgan_colab.ipynb/",
        "update": 1633087950
    },
    {
        "name": "Omnivore",
        "description": "A single model which excels at classifying images, videos, and single-view 3D data using exactly the same model parameters",
        "author": [
            [
                "Rohit Girdhar",
                "http://rohitgirdhar.github.io/"
            ],
            [
                "Mannat Singh",
                "https://scholar.google.com/citations?user=QOO8OCcAAAAJ"
            ],
            [
                "Nikhila Ravi",
                "https://nikhilaravi.com/"
            ],
            [
                "Laurens Maaten",
                "https://lvdmaaten.github.io/"
            ],
            [
                "Armand Joulin",
                "https://ai.facebook.com/people/armand-joulin/"
            ],
            [
                "Ishan Misra",
                "https://imisra.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://facebookresearch.github.io/omnivore/"
            ],
            [
                "git",
                "https://github.com/facebookresearch/omnivore",
                492
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.08377"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/akhaliq/omnivore"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2206.08356"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/dataset/epic-kitchens-100"
            ]
        ],
        "tir_url": "{tir_base_url}/github/facebookresearch/omnivore/blob/main/inference_tutorial.ipynb/",
        "update": 1655205394
    },
    {
        "name": "ESM",
        "description": "Evolutionary Scale Modeling: Pretrained language models for proteins",
        "author": [
            [
                "Zeming Lin",
                "https://research.facebook.com/people/lin-zeming/"
            ],
            [
                "Roshan Rao",
                "https://rmrao.github.io/"
            ],
            [
                "Brian Hie",
                "https://brianhie.com/"
            ],
            [
                "Zhongkai Zhu",
                "https://www.linkedin.com/in/zhongkai-zhu-03a27424"
            ],
            [
                "Allan dos Santos Costa",
                "https://scholar.google.com/citations?user=Zb4RsFsAAAAJ"
            ],
            [
                "Maryam Fazel-Zarandi",
                "https://www.maryamfazel.com/"
            ],
            [
                "Tom Sercu",
                "https://tom.sercu.me/"
            ],
            [
                "Salvatore Candido",
                "https://scholar.google.com/citations?user=BDgbhmEAAAAJ"
            ],
            [
                "Alexander Rives",
                "https://scholar.google.com/citations?user=vqb78-gAAAAJ"
            ],
            [
                "Joshua Meier",
                "https://scholar.google.com/citations?user=2M0OltAAAAAJ"
            ],
            [
                "Robert Verkuil",
                "https://dblp.org/pid/296/8930.html"
            ],
            [
                "Jason Liu",
                "https://www.linkedin.com/in/liujiayi/"
            ],
            [
                "Chloe Hsu",
                "https://chloe-hsu.com/"
            ],
            [
                "Adam Lerer",
                "https://scholar.google.com/citations?user=Ad6O4-0AAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/esm",
                2036
            ],
            [
                "huggingface",
                "https://huggingface.co/docs/transformers/model_doc/esm"
            ],
            [
                "paper",
                "https://doi.org/10.1101/2022.07.20.500902"
            ],
            [
                "paper",
                "https://doi.org/10.1101/2021.07.09.450648"
            ],
            [
                "paper",
                "https://doi.org/10.1101/2022.04.10.487779"
            ],
            [
                "ICML",
                "https://proceedings.mlr.press/v139/rao21a.html"
            ],
            [
                "pubmed",
                "https://pubmed.ncbi.nlm.nih.gov/33876751/"
            ],
            [
                "paper",
                "https://doi.org/10.1101/2022.12.21.521521"
            ],
            [
                "ESM Atlas",
                "https://esmatlas.com/"
            ],
            [
                "doi",
                "https://doi.org/10.1101/622803"
            ],
            [
                "FSDP",
                "https://fairscale.readthedocs.io/en/stable/api/nn/fsdp.html"
            ],
            [
                "data",
                "https://ftp.uniprot.org/pub/databases/uniprot/previous_releases/release-2018_03/uniref/"
            ],
            [
                "youtube",
                "https://youtu.be/N-eisTvUYrk"
            ],
            [
                "youtube",
                "https://youtu.be/GHoE4VkDehY"
            ],
            [
                "git",
                "https://github.com/sokrypton/ColabFold"
            ]
        ],
        "tir_url": "{tir_base_url}/github/sokrypton/ColabFold/blob/main/ESMFold.ipynb/",
        "update": 1667401598
    },
    {
        "name": "MoCo",
        "description": "Momentum Contrast for unsupervised visual representation learning",
        "author": [
            [
                "Kaiming He",
                "https://kaiminghe.github.io/"
            ],
            [
                "Haoqi Fan",
                "https://haoqifan.github.io/"
            ],
            [
                "Yuxin Wu",
                "https://ppwwyyxx.com/"
            ],
            [
                "Saining Xie",
                "http://sainingxie.com/"
            ],
            [
                "Ross Girshick",
                "https://www.rossgirshick.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/moco",
                4045
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.05722"
            ],
            [
                "doi",
                "https://doi.org/10.1109/CVPR42600.2020.00975"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.04297"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.02677"
            ],
            [
                "git",
                "https://github.com/ppwwyyxx/moco.tensorflow"
            ],
            [
                "youtube",
                "https://youtu.be/LvHwBQF14zs"
            ],
            [
                "youtube",
                "https://youtu.be/4VVGtYPM8JE"
            ],
            [
                "youtube",
                "https://youtu.be/o5Qh61dLDf0"
            ]
        ],
        "tir_url": "{tir_base_url}/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb/",
        "update": 1597942578
    },
    {
        "name": "Segment Anything",
        "description": "The Segment Anything Model produces high quality object masks from input prompts such as points or boxes, and it can be used to generate masks for all objects in an image",
        "author": [
            [
                "Alexander Kirillov",
                "https://alexander-kirillov.github.io/"
            ],
            [
                "Eric Mintun",
                "https://ericmintun.github.io/"
            ],
            [
                "Nikhila Ravi",
                "https://nikhilaravi.com/"
            ],
            [
                "Hanzi Mao",
                "https://hanzimao.me/"
            ],
            [
                "Chloé Rolland",
                "https://www.linkedin.com/in/chlo%C3%A9-rolland-223135a/"
            ],
            [
                "Laura Gustafson",
                "https://scholar.google.com/citations?user=c8IpF9gAAAAJ"
            ],
            [
                "Tete Xiao",
                "https://tetexiao.com/"
            ],
            [
                "Spencer Whitehead",
                "https://www.spencerwhitehead.com/"
            ],
            [
                "Alex Berg",
                "http://acberg.com/"
            ],
            [
                "Wan-Yen Lo",
                "https://github.com/wanyenlo"
            ],
            [
                "Piotr Dollar",
                "https://pdollar.github.io/"
            ],
            [
                "Ross Girshick",
                "https://www.rossgirshick.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/segment-anything",
                33747
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2304.02643"
            ],
            [
                "blog post",
                "https://ai.facebook.com/research/publications/segment-anything/"
            ],
            [
                "website",
                "https://segment-anything.com/"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/"
            ],
            [
                "data",
                "https://ai.facebook.com/datasets/segment-anything/"
            ],
            [
                "youtube",
                "https://youtu.be/2O_vecl28OA"
            ],
            [
                "youtube",
                "https://youtu.be/fVeW9a6wItM"
            ],
            [
                "youtube",
                "https://youtu.be/FjYE0tKWOiY"
            ]
        ],
        "tir_url": "{tir_base_url}/github/facebookresearch/segment-anything/blob/main/notebooks/predictor_example.ipynb/",
        "update": 1681141817
    },
    {
        "name": "CartoonGAN",
        "description": "The implementation of the cartoon GAN model with PyTorch",
        "author": [
            [
                "Tobias Sunderdiek",
                "https://github.com/TobiasSunderdiek"
            ]
        ],
        "links": [
            [
                "CVPR",
                "http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"
            ],
            [
                "project",
                "https://tobiassunderdiek.github.io/cartoon-gan/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/alamson/safebooru"
            ]
        ],
        "tir_url": "{tir_base_url}/github/TobiasSunderdiek/cartoon-gan/blob/master/CartoonGAN.ipynb/",
        "update": 1637764342
    },
    {
        "name": "VToonify",
        "description": "Leverages the mid- and high-resolution layers of StyleGAN to render high-quality artistic portraits based on the multi-scale content features extracted by an encoder to better preserve the frame details",
        "author": [
            [
                "Shuai Yang",
                "https://williamyang1991.github.io/"
            ],
            [
                "Liming Jiang",
                "https://liming-jiang.com/"
            ],
            [
                "Ziwei Liu",
                "https://liuziwei7.github.io/"
            ],
            [
                "Chen Change Loy",
                "https://www.mmlab-ntu.com/person/ccloy/"
            ]
        ],
        "links": [
            [
                "project",
                "https://www.mmlab-ntu.com/project/vtoonify/"
            ],
            [
                "git",
                "https://github.com/williamyang1991/VToonify",
                3148
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.11224"
            ],
            [
                "youtube",
                "https://youtu.be/0_OmVhDgYuY"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/PKUWilliamYang/VToonify"
            ],
            [
                "huggingface",
                "https://huggingface.co/PKUWilliamYang/VToonify/tree/main/models"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/zllrunning/face-parsing.PyTorch"
            ],
            [
                "git",
                "https://github.com/zhujiapeng/LowRankGAN"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2001.02890"
            ]
        ],
        "tir_url": "{tir_base_url}/github/williamyang1991/VToonify/blob/master/notebooks/inference_playground.ipynb/",
        "update": 1665103918
    },
    {
        "name": "DualStyleGAN",
        "description": "More challenging exemplar-based high-resolution portrait style transfer by introducing a novel DualStyleGAN with flexible control of dual styles of the original face domain and the extended artistic portrait domain",
        "author": [
            [
                "Shuai Yang",
                "https://williamyang1991.github.io/"
            ],
            [
                "Liming Jiang",
                "https://liming-jiang.com/"
            ],
            [
                "Ziwei Liu",
                "https://liuziwei7.github.io/"
            ],
            [
                "Chen Change Loy",
                "https://www.mmlab-ntu.com/person/ccloy/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/williamyang1991/DualStyleGAN",
                1431
            ],
            [
                "project",
                "https://www.mmlab-ntu.com/project/dualstylegan/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.13248"
            ],
            [
                "youtube",
                "https://youtu.be/scZTu77jixI"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/Gradio-Blocks/DualStyleGAN"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/hysts/DualStyleGAN"
            ],
            [
                "data",
                "https://cs.nju.edu.cn/rl/WebCaricature.htm"
            ],
            [
                "data",
                "https://www.gwern.net/Crops#danbooru2019-portraits"
            ],
            [
                "git",
                "https://github.com/lowfuel/progrock-stable"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/TreB1eN/InsightFace_Pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/williamyang1991/DualStyleGAN/blob/master/notebooks/inference_playground.ipynb/",
        "update": 1648104815
    },
    {
        "name": "GP-UNIT",
        "description": "Novel framework, Generative Prior-guided UNsupervised Image-to-image Translation, to improve the overall quality and applicability of the translation algorithm",
        "author": [
            [
                "Shuai Yang",
                "https://williamyang1991.github.io/"
            ],
            [
                "Liming Jiang",
                "https://liming-jiang.com/"
            ],
            [
                "Ziwei Liu",
                "https://liuziwei7.github.io/"
            ],
            [
                "Chen Change Loy",
                "https://www.mmlab-ntu.com/person/ccloy/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/williamyang1991/GP-UNIT",
                143
            ],
            [
                "project",
                "https://www.mmlab-ntu.com/project/gpunit/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.03641"
            ],
            [
                "youtube",
                "https://youtu.be/dDApWs_oDrM"
            ],
            [
                "git",
                "https://github.com/clovaai/stargan-v2#datasets-and-pre-trained-networks"
            ],
            [
                "git",
                "https://github.com/switchablenorms/CelebAMask-HQ"
            ],
            [
                "git",
                "https://github.com/NVlabs/metfaces-dataset"
            ],
            [
                "ImageNet",
                "https://image-net.org/download.php"
            ],
            [
                "git",
                "https://github.com/TreB1eN/InsightFace_Pytorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/SPADE"
            ],
            [
                "git",
                "https://github.com/nvlabs/imaginaire"
            ]
        ],
        "tir_url": "{tir_base_url}/github/williamyang1991/GP-UNIT/blob/main/notebooks/inference_playground.ipynb/",
        "update": 1648897110
    },
    {
        "name": "YOLOv3",
        "description": "You Only Look Once",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov3",
                9522
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov3"
            ],
            [
                "data",
                "http://cocodataset.org/#upload"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/coco128"
            ]
        ],
        "tir_url": "{tir_base_url}/github/ultralytics/yolov3/blob/master/tutorial.ipynb/",
        "update": 1682106110
    },
    {
        "name": "YOLOv5",
        "description": "You Only Look Once",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov5",
                38987
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov5"
            ],
            [
                "data",
                "http://cocodataset.org/#upload"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/coco128"
            ]
        ],
        "tir_url": "{tir_base_url}/github/ultralytics/yolov5/blob/master/tutorial.ipynb/",
        "update": 1682106449
    },
    {
        "name": "YOLOv6",
        "description": "Single-stage object detection framework dedicated to industrial applications",
        "author": [
            [
                "Kaiheng Weng",
                "https://github.com/khwengXU"
            ],
            [
                "Meng Cheng",
                "https://github.com/MTChengMeng"
            ],
            [
                "Yiduo Li",
                "https://github.com/yili123123"
            ],
            [
                "Xiangxiang Chu",
                "https://scholar.google.com/citations?&user=jn21pUsAAAAJ"
            ],
            [
                "Xiaolin Wei",
                "https://scholar.google.com/citations?user=s5b7lU4AAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/meituan/YOLOv6",
                4999
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.02976"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2301.05586"
            ],
            [
                "youtube",
                "https://youtu.be/3OpwcGU7VvE"
            ],
            [
                "youtube",
                "https://youtu.be/GJ0lVOE3a7c"
            ],
            [
                "youtube",
                "https://youtu.be/3hqkbqJ5ag8"
            ],
            [
                "data",
                "https://cocodataset.org/#download"
            ],
            [
                "docs",
                "https://yolov6-docs.readthedocs.io/zh_CN/latest/"
            ],
            [
                "git",
                "https://github.com/FeiGeChuanShu/ncnn-android-yolov6"
            ],
            [
                "git",
                "https://github.com/DefTruth/lite.ai.toolkit/blob/main/lite/ort/cv/yolov6.cpp"
            ],
            [
                "git",
                "https://github.com/Linaom1214/TensorRT-For-YOLO-Series"
            ],
            [
                "git",
                "https://github.com/zhiqwang/yolov5-rt-stack/tree/main/deployment/tensorrt-yolov6"
            ],
            [
                "youtube",
                "https://youtu.be/fFCWrMFH2UY"
            ],
            [
                "blog post",
                "https://learnopencv.com/yolov6-object-detection/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/meituan/YOLOv6/blob/master/turtorial.ipynb/",
        "update": 1676372004
    },
    {
        "name": "YOLOv7",
        "description": "Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors",
        "author": [
            [
                "Chien-Yao Wang",
                "https://scholar.google.com/citations?user=DkQh4M4AAAAJ"
            ],
            [
                "Alexey Bochkovskiy",
                "http://www.alexeyab.com/"
            ],
            [
                "Mark Liao",
                "https://www.iis.sinica.edu.tw/pages/liao/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/WongKinYiu/yolov7",
                10256
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2207.02696"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/sota/real-time-object-detection-on-coco?p=yolov7-trainable-bag-of-freebies-sets-new"
            ],
            [
                "data",
                "http://images.cocodataset.org/annotations/annotations_trainval2017.zip"
            ],
            [
                "data",
                "http://images.cocodataset.org/zips/train2017.zip"
            ],
            [
                "data",
                "http://images.cocodataset.org/zips/val2017.zip"
            ],
            [
                "data",
                "https://github.com/WongKinYiu/yolov7/releases/download/v0.1/coco2017labels-segments.zip"
            ],
            [
                "git",
                "https://github.com/WongKinYiu/yolor"
            ],
            [
                "git",
                "https://github.com/WongKinYiu/PyTorch_YOLOv4"
            ],
            [
                "git",
                "https://github.com/WongKinYiu/ScaledYOLOv4"
            ],
            [
                "git",
                "https://github.com/Megvii-BaseDetection/YOLOX"
            ],
            [
                "git",
                "https://github.com/DingXiaoH/RepVGG"
            ],
            [
                "git",
                "https://github.com/JUGGHM/OREPA_CVPR2022"
            ],
            [
                "git",
                "https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PL_Nji0JOuXg2QMohGK7wfzgJ-MavzXRHW"
            ],
            [
                "youtube",
                "https://youtu.be/-QWxJ0j9EY8"
            ]
        ],
        "tir_url": "{tir_base_url}/github/WongKinYiu/yolov7/blob/main/tools/compare_YOLOv7_vs_YOLOv5m6_half.ipynb/",
        "update": 1660013207
    },
    {
        "name": "Instance-aware Image Colorization",
        "description": "Novel deep learning framework to achieve instance-aware colorization",
        "author": [
            [
                "Jheng-Wei Su",
                "https://github.com/ericsujw"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2005.10825"
            ],
            [
                "git",
                "https://github.com/ericsujw/InstColorization",
                668
            ],
            [
                "project",
                "https://ericsujw.github.io/InstColorization/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=Zj1N4uE1ehk"
            ]
        ],
        "tir_url": "{tir_base_url}/github/ericsujw/InstColorization/blob/master/InstColorization.ipynb/",
        "update": 1598775300
    },
    {
        "name": "Adversarial Patch",
        "description": "A method to create universal, robust, targeted adversarial image patches in the real world",
        "author": [
            [
                "Tom Brown",
                "https://github.com/nottombrown"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1712.09665"
            ]
        ],
        "tir_url": "{tir_base_url}/github/cleverhans-lab/cleverhans/blob/master/examples/adversarial_patch/AdversarialPatch.ipynb/",
        "update": 1611753006
    },
    {
        "name": "MakeItTalk",
        "description": "A method that generates expressive talking-head videos from a single facial image with audio as the only input",
        "author": [
            [
                "Yang Zhou",
                "https://people.umass.edu/~yangzhou/"
            ],
            [
                "Xintong Han",
                "http://users.umiacs.umd.edu/~xintong/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Jose Echevarria",
                "http://www.jiechevarria.com/"
            ],
            [
                "Evangelos Kalogerakis",
                "https://people.cs.umass.edu/~kalo/"
            ],
            [
                "Dingzeyu Li",
                "https://dingzeyu.li/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.12992"
            ],
            [
                "project",
                "https://people.umass.edu/~yangzhou/MakeItTalk/"
            ],
            [
                "git",
                "https://github.com/yzhou359/MakeItTalk",
                777
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=vUMGKASgbf8"
            ],
            [
                "data",
                "https://drive.google.com/drive/folders/1EwuAy3j1b9Zc1MsidUfxG_pJGc_cV60O"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yzhou359/MakeItTalk/blob/master/quick_demo.ipynb/",
        "update": 1605032339
    },
    {
        "name": "Taming Transformers for High-Resolution Image Synthesis",
        "description": "We combine the efficiancy of convolutional approaches with the expressivity of transformers by introducing a convolutional VQGAN, which learns a codebook of context-rich visual parts, whose composition is modeled with an autoregressive transformer",
        "author": [
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Björn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "git",
                "https://github.com/CompVis/taming-transformers",
                4291
            ],
            [
                "project",
                "https://compvis.github.io/taming-transformers/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb/",
        "update": 1642092607
    },
    {
        "name": "Geometry-Free View Synthesis",
        "description": "Is a geometric model required to synthesize novel views from a single image?",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Björn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2104.07652"
            ],
            [
                "data",
                "https://google.github.io/realestate10k/"
            ],
            [
                "git",
                "https://github.com/CompVis/geometry-free-view-synthesis",
                322
            ],
            [
                "git",
                "https://github.com/colmap/colmap"
            ]
        ],
        "tir_url": "{tir_base_url}/github/CompVis/geometry-free-view-synthesis/blob/master/scripts/braindance.ipynb/",
        "update": 1619088073
    },
    {
        "name": "Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes",
        "description": "A method to stylize images by optimizing parameterized brushstrokes instead of pixels",
        "author": [
            [
                "Dmytro Kotovenko",
                "https://scholar.google.de/citations?user=T_U8yxwAAAAJ"
            ],
            [
                "Matthias Wright",
                "https://matthias-wright.github.io/"
            ],
            [
                "Arthur Heimbrecht",
                "https://github.com/arwehei"
            ],
            [
                "Björn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ]
        ],
        "links": [
            [
                "project",
                "https://compvis.github.io/brushstroke-parameterized-style-transfer/"
            ],
            [
                "git",
                "https://github.com/CompVis/brushstroke-parameterized-style-transfer",
                156
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17185"
            ]
        ],
        "tir_url": "{tir_base_url}/github/CompVis/brushstroke-parameterized-style-transfer/blob/tensorflow_v2/notebooks/BrushstrokeStyleTransfer_TF2.ipynb/",
        "update": 1622625301
    },
    {
        "name": "LDM",
        "description": "High-Resolution Image Synthesis with Latent Diffusion Models",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Andreas Blattmann",
                "https://github.com/ablattmann"
            ],
            [
                "Dominik Lorenz",
                "https://github.com/qp-qp"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Björn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/CompVis/latent-diffusion",
                7690
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.10752"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.02114"
            ],
            [
                "git",
                "https://github.com/fyu/lsun"
            ],
            [
                "git",
                "https://github.com/openai/guided-diffusion"
            ],
            [
                "git",
                "https://github.com/lucidrains/denoising-diffusion-pytorch"
            ],
            [
                "git",
                "https://github.com/lucidrains/x-transformers"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/multimodalart/latentdiffusion"
            ]
        ],
        "tir_url": "{tir_base_url}/github/CompVis/latent-diffusion/blob/master/scripts/latent_imagenet_diffusion.ipynb/",
        "update": 1649074668
    },
    {
        "name": "NFNet",
        "description": "An adaptive gradient clipping technique, a significantly improved class of Normalizer-Free ResNets",
        "author": [
            [
                "Andrew Brock",
                "https://github.com/ajbrock"
            ],
            [
                "Soham De",
                "https://sohamde.github.io/"
            ],
            [
                "Samuel L. Smith",
                "https://scholar.google.co.uk/citations?user=fyEqU5oAAAAJ"
            ],
            [
                "Karen Simonyan",
                "https://scholar.google.com/citations?user=L7lMQkQAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2102.06171"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2101.08692"
            ],
            [
                "git",
                "https://github.com/deepmind/deepmind-research/tree/master/nfnets",
                11861
            ],
            [
                "git",
                "https://github.com/deepmind/jaxline"
            ]
        ],
        "tir_url": "{tir_base_url}/github/deepmind/deepmind-research/blob/master/nfnets/nfnet_demo_colab.ipynb/",
        "update": 1613580176
    },
    {
        "name": "Skillful Precipitation Nowcasting Using Deep Generative Models of Radar",
        "description": "Open-sourced dataset and model snapshot for precipitation nowcasting",
        "author": [
            [
                "Suman Ravuri",
                "https://www.linkedin.com/in/suman-ravuri-81928082"
            ],
            [
                "Karel Lenc",
                "https://www.robots.ox.ac.uk/~karel/"
            ],
            [
                "Matthew Willson",
                "https://www.linkedin.com/in/matthew-willson-6a1b422"
            ],
            [
                "Dmitry Kangin",
                "https://scholar.google.com/citations?user=vv-leaMAAAAJ"
            ],
            [
                "Rémi Lam",
                "https://scholar.google.com/citations?user=Sm7xCbEAAAAJ"
            ],
            [
                "Piotr Mirowski",
                "https://piotrmirowski.com/"
            ],
            [
                "Maria Athanassiadou",
                "https://scholar.google.com/citations?user=VtkgHP0AAAAJ"
            ],
            [
                "Sheleem Kashem",
                "https://www.linkedin.com/in/sheleemkashem/"
            ],
            [
                "Rachel Prudden",
                "https://computerscience.exeter.ac.uk/staff/rep218"
            ],
            [
                "Amol Mandhane",
                "https://github.com/amol-mandhane"
            ],
            [
                "Aidan Clark",
                "https://scholar.google.com/citations?user=_19DrfIAAAAJ"
            ],
            [
                "Andrew Brock",
                "https://github.com/ajbrock"
            ],
            [
                "Karen Simonyan",
                "https://scholar.google.com/citations?user=L7lMQkQAAAAJ"
            ],
            [
                "Raia Hadsell",
                "https://github.com/raiah"
            ],
            [
                "Niall Robinson",
                "https://github.com/niallrobinson"
            ],
            [
                "Ellen Clancy",
                "https://www.linkedin.com/in/ellen-clancy-815967124"
            ],
            [
                "Shakir Mohamed",
                "https://www.shakirm.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2104.00954"
            ],
            [
                "git",
                "https://github.com/deepmind/deepmind-research/tree/master/nowcasting",
                11861
            ],
            [
                "tf",
                "https://www.tensorflow.org/hub"
            ],
            [
                "local kernel",
                "https://research.google.com/colaboratory/local-runtimes.html"
            ],
            [
                "blog post",
                "https://deepmind.com/blog/article/nowcasting"
            ],
            [
                "paper",
                "https://www.nature.com/articles/s41586-021-03854-z"
            ]
        ],
        "tir_url": "{tir_base_url}/github/deepmind/deepmind-research/blob/master/nowcasting/Open_sourced_dataset_and_model_snapshot_for_precipitation_nowcasting.ipynb/",
        "update": 1632920430
    },
    {
        "name": "AlphaFold",
        "description": "Highly accurate protein structure prediction",
        "author": [
            [
                "John Jumper",
                "https://scholar.google.com/citations?user=a5goOh8AAAAJ"
            ],
            [
                "Richard Evans",
                "http://www.doc.ic.ac.uk/~re14/"
            ],
            [
                "Alexander Pritzel",
                "https://scholar.google.com/citations?user=GPgAyU0AAAAJ"
            ],
            [
                "Tim Green",
                "http://tfgg.me/"
            ],
            [
                "Michael Figurnov",
                "https://figurnov.ru/"
            ],
            [
                "Olaf Ronneberger",
                "https://lmb.informatik.uni-freiburg.de/people/ronneber/"
            ],
            [
                "Kathryn Tunyasuvunakool",
                "https://scholar.google.com/citations?user=eEqNGagAAAAJ"
            ],
            [
                "Russ Bates",
                "https://scholar.google.com/citations?user=Koes5ewAAAAJ"
            ],
            [
                "Augustin Žídek",
                "https://augustin.zidek.eu/"
            ],
            [
                "Anna Potapenko",
                "http://apotapenko.com/"
            ],
            [
                "Alex Bridgland",
                "https://scholar.google.com/citations?user=VWmXKPMAAAAJ"
            ],
            [
                "Clemens Meyer",
                "https://scholar.google.com/citations?user=EWLZiM8AAAAJ"
            ],
            [
                "Simon Kohl",
                "https://www.simonkohl.com/"
            ],
            [
                "Andrew Ballard",
                "https://scholar.google.com/citations?user=syjQhAMAAAAJ"
            ],
            [
                "Bernardino Romera-Paredes",
                "https://sites.google.com/site/romeraparedes/"
            ],
            [
                "Stanislav Nikolov",
                "https://scholar.google.co.uk/citations?user=O-b7pBEAAAAJ"
            ],
            [
                "Rishub Jain",
                "http://rishub.me/"
            ]
        ],
        "links": [
            [
                "paper",
                "https://www.nature.com/articles/s41586-021-03819-2"
            ],
            [
                "paper",
                "https://www.nature.com/articles/s41586-021-03828-1"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/AlphaFold"
            ],
            [
                "git",
                "https://github.com/deepmind/alphafold/",
                10368
            ],
            [
                "blog post",
                "https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"
            ],
            [
                "blog post",
                "https://deepmind.com/blog/article/putting-the-power-of-alphafold-into-the-worlds-hands"
            ],
            [
                "git",
                "https://github.com/deepmind/tree"
            ],
            [
                "git",
                "https://github.com/deepmind/chex"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=gg7WjuFs8F4"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=B9PL__gVxLI"
            ],
            [
                "paperswithcode",
                "https://paperswithcode.com/method/alphafold"
            ]
        ],
        "tir_url": "{tir_base_url}/github/deepmind/alphafold/blob/master/notebooks/AlphaFold.ipynb/",
        "update": 1683108232
    },
    {
        "name": "Arnheim",
        "description": "Generative Art Using Neural Visual Grammars and Dual Encoders",
        "author": [
            [
                "Chrisantha Fernando",
                "https://www.chrisantha.co.uk/"
            ],
            [
                "Ali Eslami",
                "http://arkitus.com/"
            ],
            [
                "Jean-Baptiste Alayrac",
                "https://www.jbalayrac.com/"
            ],
            [
                "Piotr Mirowski",
                "https://piotrmirowski.com/"
            ],
            [
                "Dylan Banarse",
                "https://www.2ne1.com/"
            ],
            [
                "Simon Osindero",
                "https://scholar.google.com/citations?user=Jq8ZS5kAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2105.00162"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.14843"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.07729"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.02580"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1609.09106"
            ],
            [
                "git",
                "https://github.com/deepmind/arnheim",
                237
            ],
            [
                "git",
                "https://github.com/openai/dall-e"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Compositional_pattern-producing_network"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=U7guaMdeF4g"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=zh0goLbS-l0"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=SYJGNt7yu6M"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=MxkYKa0x5AU"
            ]
        ],
        "tir_url": "{tir_base_url}/github/deepmind/arnheim/blob/master/arnheim_2.ipynb/",
        "update": 1636631416
    },
    {
        "name": "Functa",
        "description": "From data to functa: Your data point is a function and you can treat it like one",
        "author": [
            [
                "Emilien Dupont",
                "https://emiliendupont.github.io/"
            ],
            [
                "Hyunjik Kim",
                "https://hyunjik11.github.io/"
            ],
            [
                "Ali Eslami",
                "http://arkitus.com/"
            ],
            [
                "Danilo Rezende",
                "https://danilorezende.com/about/"
            ],
            [
                "Dan Rosenbaum",
                "https://danrsm.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/functa",
                91
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.12204"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/celeb_a_hq"
            ],
            [
                "git",
                "https://github.com/sxyu/pixel-nerf"
            ],
            [
                "git",
                "https://github.com/deepmind/jaxline"
            ]
        ],
        "tir_url": "{tir_base_url}/github/deepmind/functa/blob/main/modulation_visualization_colab.ipynb/",
        "update": 1664003206
    },
    {
        "name": "AlphaTensor",
        "description": "Discovering faster matrix multiplication algorithms with reinforcement learning",
        "author": [
            [
                "Alhussein Fawzi",
                "http://www.alhusseinfawzi.info/"
            ],
            [
                "Matej Balog",
                "http://matejbalog.eu/"
            ],
            [
                "Aja Huang",
                "https://en.wikipedia.org/wiki/Aja_Huang"
            ],
            [
                "Thomas Hubert",
                "https://scholar.google.com/citations?user=WXG0QfMAAAAJ"
            ],
            [
                "Bernardino Romera-Paredes",
                "https://sites.google.com/site/romeraparedes/"
            ],
            [
                "Mohammadamin Barekatain",
                "http://barekatain.me/"
            ],
            [
                "Alexander Novikov",
                "https://scholar.google.com/citations?user=jMUkLqwAAAAJ"
            ],
            [
                "Francisco Ruiz",
                "https://franrruiz.github.io/"
            ],
            [
                "Julian Schrittwieser",
                "https://www.furidamu.org/"
            ],
            [
                "Grzegorz Swirszcz",
                "https://sites.google.com/site/grzegorzswirszcz/home"
            ],
            [
                "David Silver",
                "https://www.davidsilver.uk/"
            ],
            [
                "Demis Hassabis",
                "https://en.wikipedia.org/wiki/Demis_Hassabis"
            ],
            [
                "Pushmeet Kohli",
                "https://sites.google.com/site/pushmeet/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/alphatensor",
                2480
            ],
            [
                "paper",
                "https://www.nature.com/articles/s41586-022-05172-4"
            ],
            [
                "blog post",
                "https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor"
            ],
            [
                "youtube",
                "https://youtu.be/3N3Bl5AA5QU"
            ],
            [
                "youtube",
                "https://youtu.be/gpYnDls4PdQ"
            ],
            [
                "youtube",
                "https://youtu.be/IYgZS2EvnLI"
            ],
            [
                "youtube",
                "https://youtu.be/8ILk4Wjo5rc"
            ]
        ],
        "tir_url": "{tir_base_url}/github/deepmind/alphatensor/blob/master/nonequivalence/inspect_factorizations_notebook.ipynb/",
        "update": 1664870748
    },
    {
        "name": "Neural Style Transfer",
        "description": "Implementation of Neural Style Transfer in Keras 2.0+",
        "author": [
            [
                "Somshubra Majumdar",
                "http://titu1994.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "http://arxiv.org/abs/1508.06576"
            ],
            [
                "git",
                "https://github.com/titu1994/Neural-Style-Transfer",
                2215
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1605.04603"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.05897"
            ]
        ],
        "tir_url": "{tir_base_url}/github/titu1994/Neural-Style-Transfer/blob/master/NeuralStyleTransfer.ipynb/",
        "update": 1611304806
    },
    {
        "name": "SIREN",
        "description": "Implicit Neural Representations with Periodic Activation Functions",
        "author": [
            [
                "Vincent Sitzmann",
                "https://vsitzmann.github.io/"
            ],
            [
                "Julien Martel",
                "http://web.stanford.edu/~jnmartel/"
            ]
        ],
        "links": [
            [
                "project",
                "https://vsitzmann.github.io/siren/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.09661"
            ],
            [
                "git",
                "https://github.com/vsitzmann/siren",
                1514
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=Q2fLWGBeaiI"
            ],
            [
                "data",
                "https://drive.google.com/drive/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K"
            ]
        ],
        "tir_url": "{tir_base_url}/github/vsitzmann/siren/blob/master/explore_siren.ipynb/",
        "update": 1593031201
    },
    {
        "name": "GANSpace",
        "description": "A simple technique to analyze GANs and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day",
        "author": [
            [
                "Erik Härkönen",
                "https://github.com/harskish"
            ],
            [
                "Aaron Hertzmann",
                "http://www.dgp.toronto.edu/~hertzman/"
            ],
            [
                "Jaakko Lehtinen",
                "https://users.aalto.fi/~lehtinj7/"
            ],
            [
                "Sylvain Paris",
                "http://people.csail.mit.edu/sparis/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.02546"
            ],
            [
                "git",
                "https://github.com/harskish/ganspace",
                1730
            ],
            [
                "youtube",
                "https://youtu.be/jdTICDa_eAI"
            ],
            [
                "git",
                "https://github.com/justinpinkney/awesome-pretrained-stylegan"
            ],
            [
                "git",
                "https://github.com/CSAILVision/GANDissect"
            ]
        ],
        "tir_url": "{tir_base_url}/github/harskish/ganspace/blob/master/notebooks/Ganspace_colab.ipynb/",
        "update": 1607275506
    },
    {
        "name": "LaSAFT",
        "description": "Latent Source Attentive Frequency Transformation for Conditioned Source Separation",
        "author": [
            [
                "Woosung Choi",
                "https://ws-choi.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://lasaft.github.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11631"
            ],
            [
                "git",
                "https://github.com/ws-choi/Conditioned-Source-Separation-LaSAFT",
                80
            ],
            [
                "data",
                "https://sigsep.github.io/datasets/musdb.html"
            ]
        ],
        "tir_url": "{tir_base_url}/github/ws-choi/Conditioned-Source-Separation-LaSAFT/blob/master/colab_demo/LaSAFT_with_GPoCM_Stella_Jang_Example.ipynb/",
        "update": 1604243816
    },
    {
        "name": "Jukebox",
        "description": "A neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles",
        "author": [
            [
                "Christine Payne",
                "http://christinemcleavey.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://openai.com/blog/jukebox"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.00341"
            ],
            [
                "explorer",
                "http://jukebox.openai.com/"
            ],
            [
                "git",
                "https://github.com/openai/jukebox",
                6936
            ]
        ],
        "tir_url": "{tir_base_url}/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb/",
        "update": 1588612610
    },
    {
        "name": "GLIDE",
        "description": "Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models",
        "author": [
            [
                "Alex Nichol",
                "https://aqnichol.com/"
            ],
            [
                "Prafulla Dhariwal",
                "https://github.com/prafullasd"
            ],
            [
                "Aditya Ramesh",
                "http://adityaramesh.com/"
            ],
            [
                "Pranav Shyam",
                "https://github.com/pranv"
            ],
            [
                "Pamela Mishkin",
                "https://manlikemishap.github.io/"
            ],
            [
                "Bob McGrew",
                "https://github.com/bmcgrew"
            ],
            [
                "Ilya Sutskever",
                "http://www.cs.utoronto.ca/~ilya/"
            ],
            [
                "Mark Chen",
                "https://scholar.google.com/citations?user=5fU-QMwAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/openai/glide-text2im",
                3197
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.10741"
            ],
            [
                "youtube",
                "https://youtu.be/ItKi3h7IY2o"
            ]
        ],
        "tir_url": "{tir_base_url}/github/openai/glide-text2im/blob/master/notebooks/inpaint.ipynb/",
        "update": 1640133979
    },
    {
        "name": "CLIP",
        "description": "A neural network which efficiently learns visual concepts from natural language supervision",
        "author": [
            [
                "Jong Wook",
                "https://jongwook.kim/"
            ],
            [
                "Alec Radford",
                "http://newmu.github.io/"
            ],
            [
                "Ilya Sutskever",
                "http://www.cs.utoronto.ca/~ilya/"
            ]
        ],
        "links": [
            [
                "project",
                "https://openai.com/blog/clip/"
            ],
            [
                "git",
                "https://github.com/openai/CLIP",
                15420
            ],
            [
                "paper",
                "https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf"
            ],
            [
                "data",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ]
        ],
        "tir_url": "{tir_base_url}/github/openai/clip/blob/master/Interacting_with_CLIP.ipynb/",
        "update": 1611930123
    },
    {
        "name": "Whisper",
        "description": "Automatic speech recognition system trained on 680,000 hours of multilingual and multitask supervised data collected from the web",
        "author": [
            [
                "Alec Radford",
                "http://newmu.github.io/"
            ],
            [
                "Jong Wook Kim",
                "https://jongwook.kim/"
            ],
            [
                "Tao Xu",
                "https://github.com/bayesian"
            ],
            [
                "Greg Brockman",
                "https://gregbrockman.com/"
            ],
            [
                "Christine McLeavey",
                "http://christinemcleavey.com/"
            ],
            [
                "Ilya Sutskever",
                "http://www.cs.toronto.edu/~ilya/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/openai/whisper",
                37884
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2212.04356"
            ],
            [
                "blog post",
                "https://openai.com/research/whisper"
            ],
            [
                "git",
                "https://github.com/kkroening/ffmpeg-python"
            ],
            [
                "youtube",
                "https://youtu.be/OCBZtgQGt1I"
            ],
            [
                "youtube",
                "https://youtu.be/8SQV-B83tPU"
            ],
            [
                "youtube",
                "https://youtu.be/nE5iVtwKerA"
            ]
        ],
        "tir_url": "{tir_base_url}/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb/",
        "update": 1663769383
    },
    {
        "name": "HiDT",
        "description": "A generative image-to-image model and a new upsampling scheme that allows to apply image translation at high resolution",
        "author": [
            [
                "Denis Korzhenkov",
                "https://github.com/denkorzh"
            ],
            [
                "Gleb Sterkin",
                "https://github.com/belkakari"
            ],
            [
                "Sergey Nikolenko",
                "https://logic.pdmi.ras.ru/~sergey/"
            ],
            [
                "Victor Lempitsky",
                "http://sites.skoltech.ru/compvision/members/vilem/"
            ]
        ],
        "links": [
            [
                "project",
                "https://saic-mdal.github.io/HiDT/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.08791"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLuvGzlEQXT1KQuKrfBBEWh2f3PToxyeM5"
            ],
            [
                "git",
                "https://github.com/saic-mdal/HiDT",
                636
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=EWKAgwgqXB4"
            ]
        ],
        "tir_url": "{tir_base_url}/github/saic-mdal/hidt/blob/master/notebooks/HighResolutionDaytimeTranslation.ipynb/",
        "update": 1611513024
    },
    {
        "name": "Wav2Lip",
        "description": "A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild",
        "author": [
            [
                "Prajwal Renukanand",
                "https://github.com/prajwalkr"
            ],
            [
                "Rudrabha Mukhopadhyay",
                "https://rudrabha.github.io/"
            ],
            [
                "Vinay Namboodiri",
                "https://vinaypn.github.io/"
            ],
            [
                "C. V. Jawahar",
                "https://faculty.iiit.ac.in/~jawahar/"
            ]
        ],
        "links": [
            [
                "project",
                "http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/"
            ],
            [
                "demo",
                "http://bhaasha.iiit.ac.in/lipsync/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.10010"
            ],
            [
                "git",
                "https://github.com/Rudrabha/Wav2Lip",
                5135
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=0fXaDCZNOJc"
            ],
            [
                "data",
                "https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html"
            ]
        ],
        "tir_url": "{tir_base_url}/github/eyaler/avatars4all/blob/master/melaflefon.ipynb/",
        "update": 1680250725
    },
    {
        "name": "MSG-Net",
        "description": "Multi-style Generative Network with a novel Inspiration Layer, which retains the functionality of optimization-based approaches and has the fast speed of feed-forward networks",
        "author": [
            [
                "Hang Zhang",
                "https://hangzhang.org/"
            ],
            [
                "Kristin Dana",
                "https://www.ece.rutgers.edu/~kdana/dana.html"
            ]
        ],
        "links": [
            [
                "project",
                "http://computervisionrutgers.github.io/MSG-Net/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.06953"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=oy6pWNWBt4Y"
            ]
        ],
        "tir_url": "{tir_base_url}/github/zhanghang1989/PyTorch-Multi-Style-Transfer/blob/master/msgnet.ipynb/",
        "update": 1611603521
    },
    {
        "name": "GMCNN",
        "description": "Generative Multi-column Convolutional Neural Networks inpainting model in Keras",
        "author": [
            [
                "Tomasz Latkowski",
                "https://github.com/tlatkowski"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.08771"
            ],
            [
                "git",
                "https://github.com/tlatkowski/inpainting-gmcnn-keras",
                90
            ],
            [
                "data",
                "http://places2.csail.mit.edu/download.html"
            ],
            [
                "data",
                "https://nv-adlr.github.io/publication/partialconv-inpainting"
            ],
            [
                "git",
                "https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tlatkowski/inpainting-gmcnn-keras/blob/master/colab/Image_Inpainting_with_GMCNN_model.ipynb/",
        "update": 1565359040
    },
    {
        "name": "Siamese NN",
        "description": "Implementation of Siamese Neural Networks built upon multihead attention mechanism for text semantic similarity task",
        "author": [
            [
                "Tomasz Latkowski",
                "https://github.com/tlatkowski"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tlatkowski/multihead-siamese-nets",
                174
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/quora-question-pairs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.14599"
            ],
            [
                "git",
                "https://github.com/facebookresearch/anli/"
            ],
            [
                "data",
                "https://nlp.stanford.edu/projects/snli/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tlatkowski/multihead-siamese-nets/blob/master/colab/multihead_siamese_nets.ipynb/",
        "update": 1576789505
    },
    {
        "name": "SkyAR",
        "description": "A vision-based method for video sky replacement and harmonization, which can automatically generate realistic and dramatic sky backgrounds in videos with controllable styles",
        "author": [
            [
                "Zhengxia Zou",
                "http://www-personal.umich.edu/~zzhengxi/"
            ]
        ],
        "links": [
            [
                "project",
                "https://jiupinjia.github.io/skyar/"
            ],
            [
                "git",
                "https://github.com/jiupinjia/SkyAR",
                1943
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11800"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=zal9Ues0aOQ"
            ]
        ],
        "tir_url": "{tir_base_url}/github/jiupinjia/SkyAR/blob/master/colab_demo.ipynb/",
        "update": 1610973767
    },
    {
        "name": "GrooVAE",
        "description": "Some applications of machine learning for generating and manipulating beats and drum performances",
        "author": [
            [
                "Jon Gillick",
                "https://www.jongillick.com/"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1905.06118"
            ],
            [
                "blog post",
                "https://g.co/magenta/groovae"
            ],
            [
                "data",
                "https://g.co/magenta/groove-datasets"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=x2YLmXzovDo"
            ],
            [
                "git",
                "https://github.com/magenta/magenta/tree/main/magenta/models/music_vae",
                18501
            ],
            [
                "web app",
                "https://groove-drums.glitch.me/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tensorflow/magenta-demos/blob/master/colab-notebooks/GrooVAE.ipynb/",
        "update": 1675291230
    },
    {
        "name": "Multitrack MusicVAE",
        "description": "The models in this notebook are capable of encoding and decoding single measures of up to 8 tracks, optionally conditioned on an underlying chord",
        "author": [
            [
                "Ian Simon",
                "https://github.com/iansimon"
            ],
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Colin Raffel",
                "https://colinraffel.com//"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ],
            [
                "Douglas Eck",
                "https://github.com/douglaseck"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1806.00195"
            ],
            [
                "blog post",
                "http://g.co/magenta/multitrack"
            ]
        ],
        "tir_url": "{tir_base_url}/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb/",
        "update": 1675291230
    },
    {
        "name": "MusicVAE",
        "description": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music",
        "author": [
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Jesse Engel",
                "https://github.com/jesseengel"
            ],
            [
                "Colin Raffel",
                "https://colinraffel.com//"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ],
            [
                "Douglas Eck",
                "https://github.com/douglaseck"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1803.05428"
            ],
            [
                "blog post",
                "https://g.co/magenta/music-vae"
            ],
            [
                "youtube",
                "https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr"
            ],
            [
                "project",
                "https://magenta.tensorflow.org/music-vae"
            ]
        ],
        "tir_url": "{tir_base_url}/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb/",
        "update": 1675291230
    },
    {
        "name": "MusicXML Documentation",
        "description": "The goal of this notebook is to explore one of the magenta libraries for music",
        "author": [
            [
                "Prakruti Joshi",
                "https://github.com/prakruti-joshi"
            ],
            [
                "Falak Shah",
                "https://falaktheoptimist.github.io/"
            ],
            [
                "Twisha Naik",
                "https://github.com/twisha96"
            ]
        ],
        "links": [
            [
                "musicXML",
                "https://www.musicxml.com/for-developers/"
            ],
            [
                "magenta",
                "https://magenta.tensorflow.org/"
            ],
            [
                "music theory",
                "http://musictheoryblog.blogspot.com/2008/02/learn-music-theory.html"
            ]
        ],
        "tir_url": "{tir_base_url}/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicXML_Document_Structure_Documentation.ipynb/",
        "update": 1610118397
    },
    {
        "name": "SVG VAE",
        "description": "A colab demo for the SVG VAE model",
        "author": [
            [
                "Raphael Gontijo Lopes",
                "https://raphagl.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1904.02632"
            ],
            [
                "blog post",
                "https://magenta.tensorflow.org/svg-vae"
            ]
        ],
        "tir_url": "{tir_base_url}/github/magenta/magenta-demos/blob/master/colab-notebooks/vae_svg_decoding.ipynb/",
        "update": 1610118397
    },
    {
        "name": "Big GAN",
        "description": "Large Scale GAN Training for High Fidelity Natural Image Synthesis",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/hub"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb/",
        "update": 1610432758
    },
    {
        "name": "BERT with TPU",
        "description": "Using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models and run predictions on tuned model",
        "author": [
            [
                "Sourabh Bajaj",
                "https://sourabhbajaj.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "tf",
                "https://www.tensorflow.org/hub"
            ],
            [
                "TPU quickstart",
                "https://cloud.google.com/tpu/docs/quickstart"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb/",
        "update": 1553816432
    },
    {
        "name": "Pixel2Style2Pixel",
        "description": "Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation",
        "author": [
            [
                "Elad Richardson",
                "https://github.com/eladrich"
            ],
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Yotam Nitzan",
                "https://yotamnitzan.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://eladrich.github.io/pixel2style2pixel/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00951"
            ],
            [
                "git",
                "https://github.com/eladrich/pixel2style2pixel",
                2933
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/HuangYG123/CurricularFace"
            ],
            [
                "youtube",
                "https://youtu.be/bfvSwhqsTgM"
            ]
        ],
        "tir_url": "{tir_base_url}/github/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb/",
        "update": 1622557484
    },
    {
        "name": "ReStyle",
        "description": "A Residual-Based StyleGAN Encoder via Iterative Refinement",
        "author": [
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://yuval-alaluf.github.io/restyle-encoder/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.02699"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00951"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.02766"
            ],
            [
                "git",
                "https://github.com/yuval-alaluf/restyle-encoder",
                995
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/TreB1eN/InsightFace_Pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yuval-alaluf/restyle-encoder/blob/master/notebooks/inference_playground.ipynb/",
        "update": 1621617807
    },
    {
        "name": "encoder4editing",
        "description": "Designing an Encoder for StyleGAN Image Manipulation",
        "author": [
            [
                "Omer Tov",
                "https://github.com/omertov"
            ],
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Yotam Nitzan",
                "https://yotamnitzan.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2102.02766"
            ],
            [
                "git",
                "https://github.com/omertov/encoder4editing",
                805
            ],
            [
                "git",
                "https://github.com/eladrich/pixel2style2pixel"
            ]
        ],
        "tir_url": "{tir_base_url}/github/omertov/encoder4editing/blob/master/notebooks/inference_playground.ipynb/",
        "update": 1638458449
    },
    {
        "name": "SAM",
        "description": "Age Transformation Using a Style-Based Regression Model",
        "author": [
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://yuval-alaluf.github.io/SAM/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.02754"
            ],
            [
                "youtube",
                "https://youtu.be/X_pYC_LtBFw"
            ],
            [
                "git",
                "https://github.com/yuval-alaluf/SAM",
                500
            ],
            [
                "git",
                "https://github.com/eladrich/pixel2style2pixel"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yuval-alaluf/SAM/blob/master/notebooks/animation_inference_playground.ipynb/",
        "update": 1619414169
    },
    {
        "name": "HyperStyle",
        "description": "A hypernetwork that learns to modulate StyleGAN's weights to faithfully express a given image in editable regions of the latent space",
        "author": [
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Omer Tov",
                "https://github.com/omertov"
            ],
            [
                "Ron Mokady",
                "https://rmokady.github.io/"
            ],
            [
                "Rinon Gal",
                "https://rinongal.github.io/"
            ],
            [
                "Amit Bermano",
                "https://www.cs.tau.ac.il/~amberman/"
            ]
        ],
        "links": [
            [
                "project",
                "https://yuval-alaluf.github.io/hyperstyle/"
            ],
            [
                "git",
                "https://github.com/yuval-alaluf/hyperstyle",
                924
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.15666"
            ],
            [
                "youtube",
                "https://youtu.be/_sbXmLY2jMw"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "data",
                "https://ai.stanford.edu/~jkrause/cars/car_dataset.html"
            ],
            [
                "git",
                "https://github.com/clovaai/stargan-v2"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/TreB1eN/InsightFace_Pytorch"
            ],
            [
                "git",
                "https://github.com/HuangYG123/CurricularFace"
            ],
            [
                "git",
                "https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.03189"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09036"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.07727"
            ],
            [
                "git",
                "https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py"
            ],
            [
                "git",
                "https://github.com/dvschultz/stylegan2-ada-pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yuval-alaluf/hyperstyle/blob/master/notebooks/inference_playground.ipynb/",
        "update": 1638512893
    },
    {
        "name": "Talking Head Anime from a Single Image",
        "description": "The network takes as input an image of an anime character's face and a desired pose, and it outputs another image of the same character in the given pose",
        "author": [
            [
                "Pramook Khungurn",
                "https://pkhungurn.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://pkhungurn.github.io/talking-head-anime/"
            ],
            [
                "youtube",
                "https://youtu.be/kMQCERkTdO0"
            ],
            [
                "youtube",
                "https://youtu.be/T1Gp-RxFZwU"
            ],
            [
                "youtube",
                "https://youtu.be/FioRJ6x_RbI"
            ],
            [
                "git",
                "https://github.com/pkhungurn/talking-head-anime-demo",
                1885
            ],
            [
                "git",
                "https://github.com/lincolnhard/head-pose-estimation"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Virtual_YouTuber"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/MikuMikuDance"
            ]
        ],
        "tir_url": "{tir_base_url}/github/pkhungurn/talking-head-anime-demo/blob/master/tha_colab.ipynb/",
        "update": 1614112707
    },
    {
        "name": "AnimeGANv2",
        "description": "An improved version of AnimeGAN - it prevents the generation of high-frequency artifacts by simply changing the normalization of features in the network",
        "author": [
            [
                "Xin Chen",
                "https://dl.acm.org/profile/99659508903"
            ],
            [
                "Gang Liu",
                "https://dl.acm.org/profile/81493643454"
            ],
            [
                "bryandlee",
                "https://github.com/bryandlee"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/bryandlee/animegan2-pytorch",
                4188
            ],
            [
                "git",
                "https://github.com/TachibanaYoshino/AnimeGANv2"
            ],
            [
                "git",
                "https://github.com/TachibanaYoshino/AnimeGAN"
            ],
            [
                "project",
                "https://tachibanayoshino.github.io/AnimeGANv2/"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/akhaliq/AnimeGANv2"
            ]
        ],
        "tir_url": "{tir_base_url}/github/bryandlee/animegan2-pytorch/blob/master/colab_demo.ipynb/",
        "update": 1637111341
    },
    {
        "name": "SkinDeep",
        "description": "Remove Body Tattoo Using Deep Learning",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/SkinDeep",
                879
            ],
            [
                "git",
                "https://github.com/jantic/DeOldify"
            ]
        ],
        "tir_url": "{tir_base_url}/github/vijishmadhavan/SkinDeep/blob/master/SkinDeep_good.ipynb/",
        "update": 1619271923
    },
    {
        "name": "ArtLine",
        "description": "A Deep Learning based project for creating line art portraits",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/ArtLine",
                3416
            ],
            [
                "git",
                "https://github.com/yiranran/APDrawingGAN"
            ],
            [
                "git",
                "https://github.com/jantic/DeOldify"
            ],
            [
                "data",
                "https://cg.cs.tsinghua.edu.cn/people/~Yongjin/APDrawingDB.zip"
            ]
        ],
        "tir_url": "{tir_base_url}/github/vijishmadhavan/Light-Up/blob/master/ArtLine(AR).ipynb/",
        "update": 1608803779
    },
    {
        "name": "StyleGAN-NADA",
        "description": "Zero-Shot non-adversarial domain adaptation of pre-trained generators",
        "author": [
            [
                "Rinon Gal",
                "https://rinongal.github.io/"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Haggai Maron",
                "https://haggaim.github.io/"
            ],
            [
                "Gal Chechik",
                "https://research.nvidia.com/person/gal-chechik"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/rinongal/StyleGAN-nada",
                1078
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch/"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17249"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.02699"
            ],
            [
                "project",
                "https://stylegan-nada.github.io/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/rinongal/stylegan-nada/blob/main/stylegan_nada.ipynb/",
        "update": 1660065154
    },
    {
        "name": "textual-inversion",
        "description": "An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion",
        "author": [
            [
                "Rinon Gal",
                "https://rinongal.github.io/"
            ],
            [
                "Yuval Alaluf",
                "https://yuval-alaluf.github.io/"
            ],
            [
                "Yuval Atzmon",
                "https://research.nvidia.com/person/yuval-atzmon"
            ],
            [
                "Or Patashnik",
                "https://orpatashnik.github.io/"
            ],
            [
                "Amit Bermano",
                "https://www.cs.tau.ac.il/~amberman/"
            ],
            [
                "Gal Chechik",
                "https://research.nvidia.com/person/gal-chechik"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://textual-inversion.github.io/"
            ],
            [
                "git",
                "https://github.com/rinongal/textual_inversion",
                2399
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2208.01618"
            ],
            [
                "youtube",
                "https://youtu.be/f3oXa7_SYek"
            ],
            [
                "youtube",
                "https://youtu.be/opD_H9bED9Y"
            ]
        ],
        "tir_url": "{tir_base_url}/github/rinongal/textual_inversion/blob/master/scripts/latent_imagenet_diffusion.ipynb/",
        "update": 1661105143
    },
    {
        "name": "Parallel WaveGAN",
        "description": "State-of-the-art non-autoregressive models to build your own great vocoder",
        "author": [
            [
                "Tomoki Hayashi",
                "https://kan-bayashi.github.io/"
            ]
        ],
        "links": [
            [
                "demo",
                "https://kan-bayashi.github.io/ParallelWaveGAN/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.11480"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.06711"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05106"
            ],
            [
                "git",
                "https://github.com/kan-bayashi/ParallelWaveGAN",
                1316
            ],
            [
                "git",
                "https://github.com/NVIDIA/tacotron2"
            ],
            [
                "git",
                "https://github.com/espnet/espnet"
            ]
        ],
        "tir_url": "{tir_base_url}/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb/",
        "update": 1680518655
    },
    {
        "name": "VideoGPT",
        "description": "A conceptually simple architecture for scaling likelihood based generative modeling to natural videos",
        "author": [
            [
                "Wilson Yan",
                "https://wilson1yan.github.io/"
            ],
            [
                "Yunzhi Zhang",
                "https://zzyunzhi.github.io/"
            ],
            [
                "Pieter Abbeel",
                "https://people.eecs.berkeley.edu/~pabbeel/"
            ],
            [
                "Aravind Srinivas",
                "https://people.eecs.berkeley.edu/~aravind/"
            ]
        ],
        "links": [
            [
                "project",
                "https://wilson1yan.github.io/videogpt/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.10157"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.10509"
            ],
            [
                "data",
                "https://www.crcv.ucf.edu/data/UCF101.php"
            ],
            [
                "git",
                "https://github.com/wilson1yan/VideoGPT",
                544
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/akhaliq/VideoGPT"
            ]
        ],
        "tir_url": "{tir_base_url}/github/wilson1yan/VideoGPT/blob/master/notebooks/Using_VideoGPT.ipynb/",
        "update": 1646240927
    },
    {
        "name": "SimSwap",
        "description": "An efficient framework, called Simple Swap, aiming for generalized and high fidelity face swapping",
        "author": [
            [
                "Xuanhong Chen",
                "https://github.com/neuralchen"
            ],
            [
                "Bingbing Ni",
                "https://scholar.google.com.sg/citations?user=eUbmKwYAAAAJ"
            ],
            [
                "Yanhao Ge",
                "https://scholar.google.com/citations?user=h6tuBAcAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2106.06340"
            ],
            [
                "git",
                "https://github.com/neuralchen/SimSwap",
                3243
            ],
            [
                "git",
                "https://github.com/deepinsight/insightface"
            ]
        ],
        "tir_url": "{tir_base_url}/github/neuralchen/SimSwap/blob/master/SimSwap%20colab.ipynb/",
        "update": 1637749144
    },
    {
        "name": "TediGAN",
        "description": "Framework for multi-modal image generation and manipulation with textual descriptions",
        "author": [
            [
                "Weihao Xia",
                "https://github.com/weihaox"
            ],
            [
                "Yujiu Yang",
                "http://www.fiesta.tsinghua.edu.cn/pi/3/24"
            ],
            [
                "Jing-Hao Xue",
                "http://www.homepages.ucl.ac.uk/~ucakjxu/"
            ],
            [
                "Baoyuan Wu",
                "https://sites.google.com/site/baoyuanwu2015/home"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2012.03308"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.08910"
            ],
            [
                "youtube",
                "https://youtu.be/L8Na2f5viAM"
            ],
            [
                "git",
                "https://github.com/IIGROUP/TediGAN",
                335
            ],
            [
                "git",
                "https://github.com/weihaox/Multi-Modal-CelebA-HQ"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch/"
            ],
            [
                "git",
                "https://github.com/fyu/lsun"
            ]
        ],
        "tir_url": "{tir_base_url}/github/weihaox/TediGAN/blob/master/playground.ipynb/",
        "update": 1625056105
    },
    {
        "name": "Anycost GAN",
        "description": "Interactive natural image editing",
        "author": [
            [
                "Ji Lin",
                "http://linji.me/"
            ],
            [
                "Richard Zhang",
                "https://richzhang.github.io/"
            ],
            [
                "Frieder Ganz",
                "https://scholar.google.com/citations?user=u9ySZkUAAAAJ"
            ],
            [
                "Song Han",
                "https://songhan.mit.edu/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mit-han-lab/anycost-gan",
                741
            ],
            [
                "project",
                "https://hanlab.mit.edu/projects/anycost-gan/"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=_yEziPl9AkM"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.03243"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/switchablenorms/CelebAMask-HQ"
            ],
            [
                "git",
                "https://github.com/fyu/lsun"
            ]
        ],
        "tir_url": "{tir_base_url}/github/mit-han-lab/anycost-gan/blob/master/notebooks/intro_colab.ipynb/",
        "update": 1658346104
    },
    {
        "name": "Rewriting a Deep Generative Model",
        "description": "We ask if a deep network can be reprogrammed to follow different rules, by enabling a user to directly change the weights, instead of training with a data set",
        "author": [
            [
                "David Bau",
                "https://people.csail.mit.edu/davidbau/home/"
            ],
            [
                "Steven Liu",
                "http://people.csail.mit.edu/stevenliu/"
            ],
            [
                "Tongzhou Wang",
                "https://ssnl.github.io/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ],
            [
                "Antonio Torralba",
                "https://groups.csail.mit.edu/vision/torralbalab/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2007.15646"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.04958"
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=i2_-zNqtEPk"
            ],
            [
                "youtube",
                "https://rewriting.csail.mit.edu/video/"
            ],
            [
                "project",
                "https://rewriting.csail.mit.edu/"
            ],
            [
                "git",
                "https://github.com/davidbau/rewriting",
                534
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/davidbau/rewriting/blob/master/notebooks/rewriting-interface.ipynb/",
        "update": 1596225732
    },
    {
        "name": "SeFa",
        "description": "A closed-form approach for unsupervised latent semantic factorization in GANs",
        "author": [
            [
                "Yujun Shen",
                "https://shenyujun.github.io/"
            ],
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://genforce.github.io/sefa/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.06600"
            ],
            [
                "git",
                "https://github.com/genforce/sefa",
                946
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=OFHW2WbXXIQ"
            ]
        ],
        "tir_url": "{tir_base_url}/github/genforce/sefa/blob/master/docs/SeFa.ipynb/",
        "update": 1607216642
    },
    {
        "name": "HiGAN",
        "description": "Semantic Hierarchy Emerges in Deep Generative Representations for Scene Synthesis",
        "author": [
            [
                "Ceyuan Yang",
                "https://ceyuan.me/"
            ],
            [
                "Yujun Shen",
                "https://shenyujun.github.io/"
            ],
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://genforce.github.io/higan/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.09267"
            ],
            [
                "git",
                "https://github.com/genforce/higan",
                151
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=X5yWu2Jwjpg"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1412.6856"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1906.10112"
            ]
        ],
        "tir_url": "{tir_base_url}/github/genforce/higan/blob/master/docs/HiGAN_Bedroom.ipynb/",
        "update": 1602644762
    },
    {
        "name": "InterFaceGAN",
        "description": "Interpreting the Latent Space of GANs for Semantic Face Editing",
        "author": [
            [
                "Yujun Shen",
                "https://shenyujun.github.io/"
            ],
            [
                "Jinjin Gu",
                "https://www.jasongt.com/"
            ],
            [
                "Xiaoou Tang",
                "https://www.ie.cuhk.edu.hk/people/xotang.shtml"
            ],
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://genforce.github.io/interfacegan/"
            ],
            [
                "git",
                "https://github.com/genforce/interfacegan",
                1364
            ],
            [
                "youtube",
                "https://www.youtube.com/watch?v=uoftpl3Bj6w"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.10786"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.09635"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "git",
                "https://github.com/tkarras/progressive_growing_of_gans"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan"
            ]
        ],
        "tir_url": "{tir_base_url}/github/genforce/interfacegan/blob/master/docs/InterFaceGAN.ipynb/",
        "update": 1602563896
    },
    {
        "name": "DALL·E Mini",
        "description": "Generate images from a text prompt",
        "author": [
            [
                "Boris Dayma",
                "https://github.com/borisdayma"
            ],
            [
                "Suraj Patil",
                "https://github.com/patil-suraj"
            ],
            [
                "Pedro Cuenca",
                "https://github.com/pcuenca"
            ],
            [
                "Khalid Saifullah",
                "https://khalidsaifullaah.github.io/"
            ],
            [
                "Tanishq Abraham",
                "https://github.com/tmabraham"
            ],
            [
                "Phúc H. Lê Khắc",
                "https://lkhphuc.com/"
            ],
            [
                "Luke Melas",
                "https://lukemelas.github.io/"
            ],
            [
                "Ritobrata Ghosh",
                "https://ghosh-r.github.io/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/flax-community/dalle-mini"
            ],
            [
                "git",
                "https://github.com/borisdayma/dalle-mini",
                14133
            ],
            [
                "git",
                "https://github.com/huggingface/transformers/tree/master/examples/research_projects/jax-projects"
            ],
            [
                "git",
                "https://github.com/openai/CLIP/blob/main/data/yfcc100m.md"
            ],
            [
                "data",
                "https://aclanthology.org/P18-1238/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.08981"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.13461"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.04015"
            ]
        ],
        "tir_url": "{tir_base_url}/github/borisdayma/dalle-mini/blob/main/tools/inference/inference_pipeline.ipynb/",
        "update": 1675994113
    },
    {
        "name": "ruDALL·E",
        "description": "Generate images from texts in Russian",
        "author": [
            [
                "Alex Shonenkov",
                "https://github.com/shonenkov"
            ]
        ],
        "links": [
            [
                "project",
                "https://rudalle.ru/"
            ],
            [
                "git",
                "https://github.com/ai-forever/ru-dalle",
                1641
            ],
            [
                "git",
                "https://github.com/bes-dev/vqvae_dwt_distiller.pytorch"
            ],
            [
                "git",
                "https://github.com/boomb0om/Real-ESRGAN-colab"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/multimodalart/rudalle"
            ]
        ],
        "tir_url": "{tir_base_url}/github/ai-forever/ru-dalle/blob/master/jupyters/ruDALLE-example-generation-A100.ipynb/",
        "update": 1635953686
    },
    {
        "name": "Music Composer",
        "description": "Synthesizing symbolic music in MIDI format using the Music Transformer model",
        "author": [
            [
                "bazanovvanya",
                "https://github.com/bazanovvanya"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/music-composer",
                64
            ],
            [
                "git",
                "https://github.com/gwinndr/MusicTransformer-Pytorch"
            ],
            [
                "git",
                "https://github.com/bytedance/GiantMIDI-Piano"
            ],
            [
                "git",
                "https://github.com/mdeff/fma"
            ],
            [
                "data",
                "https://magenta.tensorflow.org/datasets/maestro"
            ],
            [
                "data",
                "https://colinraffel.com//projects/lmd/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1909.05858"
            ],
            [
                "blog post",
                "https://habr.com/ru/company/sberbank/blog/583592/"
            ]
        ],
        "tir_url": "{tir_base_url}/github/ai-forever/music-composer/blob/master/src/Music_Composer_Demo_Colab_en.ipynb/",
        "update": 1639990820
    },
    {
        "name": "Lifespan Age Transformation Synthesis",
        "description": "Multi-domain image-to-image generative adversarial network architecture, whose learned latent space models a continuous bi-directional aging process",
        "author": [
            [
                "Roy Or-El",
                "https://homes.cs.washington.edu/~royorel/"
            ],
            [
                "Soumyadip Sengupta",
                "https://homes.cs.washington.edu/~soumya91/"
            ],
            [
                "Ohad Fried",
                "https://www.ohadf.com/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Ira Kemelmacher-Shlizerman",
                "https://www.irakemelmacher.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://grail.cs.washington.edu/projects/lifespan_age_transformation_synthesis/"
            ],
            [
                "youtube",
                "https://youtu.be/_jTFcjN2hBk"
            ],
            [
                "youtube",
                "https://youtu.be/9fulnt2_q_Y"
            ],
            [
                "git",
                "https://github.com/royorel/Lifespan_Age_Transformation_Synthesis",
                492
            ],
            [
                "git",
                "https://github.com/royorel/FFHQ-Aging-Dataset"
            ],
            [
                "git",
                "https://github.com/NVIDIA/pix2pixHD"
            ],
            [
                "git",
                "https://github.com/rosinality/style-based-gan-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.09764"
            ]
        ],
        "tir_url": "{tir_base_url}/github/royorel/Lifespan_Age_Transformation_Synthesis/blob/master/LATS_demo.ipynb/",
        "update": 1604168428
    },
    {
        "name": "Instant-NGP",
        "description": "Instant Neural Graphics Primitives with a Multiresolution Hash Encoding",
        "author": [
            [
                "Thomas Müller",
                "https://tom94.net/"
            ],
            [
                "Alex Evans",
                "https://research.nvidia.com/person/alex-evans"
            ],
            [
                "Christoph Schied",
                "https://research.nvidia.com/person/christoph-schied"
            ],
            [
                "Alexander Keller",
                "https://research.nvidia.com/person/alex-keller"
            ]
        ],
        "links": [
            [
                "project",
                "https://nvlabs.github.io/instant-ngp/"
            ],
            [
                "blog post",
                "https://developer.nvidia.com/blog/getting-started-with-nvidia-instant-nerfs/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.05989"
            ],
            [
                "tutorial",
                "https://www.nvidia.com/en-us/on-demand/session/siggraph2022-sigg22-s-16/"
            ],
            [
                "git",
                "https://github.com/NVlabs/instant-ngp",
                12733
            ],
            [
                "git",
                "https://github.com/NVlabs/tiny-cuda-nn"
            ],
            [
                "git",
                "https://github.com/IDLabMedia/large-lightfields-dataset"
            ],
            [
                "git",
                "https://github.com/nickponline/dd-nerf-dataset"
            ],
            [
                "youtube",
                "https://youtu.be/j8tMk-GE8hY"
            ],
            [
                "youtube",
                "https://youtu.be/8GbENSmdVeE"
            ],
            [
                "youtube",
                "https://youtu.be/DJ2hcC1orc4"
            ],
            [
                "youtube",
                "https://youtu.be/z3-fjYzd0BA"
            ],
            [
                "git",
                "https://github.com/ocornut/imgui"
            ],
            [
                "git",
                "https://github.com/nothings/stb"
            ]
        ],
        "tir_url": "{tir_base_url}/github/NVlabs/instant-ngp/blob/master/notebooks/instant_ngp.ipynb/",
        "update": 1674031190
    },
    {
        "name": "LaMa",
        "description": "Resolution-robust Large Mask Inpainting with Fourier Convolutions",
        "author": [
            [
                "Roman Suvorov",
                "https://github.com/windj007"
            ],
            [
                "Elizaveta Logacheva",
                "https://github.com/elimohl"
            ],
            [
                "Anton Mashikhin",
                "https://www.linkedin.com/in/heyt0ny/"
            ],
            [
                "Anastasia Remizova",
                "https://github.com/feathernox"
            ],
            [
                "Arsenii Ashukha",
                "https://ashukha.com/"
            ],
            [
                "Aleksei Silvestrov",
                "https://www.linkedin.com/in/%D0%B0%D0%BB%D0%B5%D0%BA%D1%81%D0%B5%D0%B9-%D1%81%D0%B8%D0%BB%D1%8C%D0%B2%D0%B5%D1%81%D1%82%D1%80%D0%BE%D0%B2-141b99b6/"
            ],
            [
                "Naejin Kong",
                "https://github.com/naejin-kong"
            ],
            [
                "Harshith Goka",
                "https://github.com/h9399-goka"
            ],
            [
                "Kiwoong Park",
                "https://github.com/kyoong-park"
            ],
            [
                "Victor Lempitsky",
                "http://sites.skoltech.ru/compvision/members/vilem/"
            ]
        ],
        "links": [
            [
                "project",
                "https://saic-mdal.github.io/lama-project/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.07161"
            ],
            [
                "git",
                "https://github.com/saic-mdal/lama",
                5608
            ],
            [
                "git",
                "https://github.com/andy971022/auto-lama"
            ],
            [
                "git",
                "https://github.com/richzhang/PerceptualSimilarity"
            ],
            [
                "git",
                "https://github.com/Po-Hsun-Su/pytorch-ssim"
            ],
            [
                "git",
                "https://github.com/mseitzer/pytorch-fid"
            ]
        ],
        "tir_url": "{tir_base_url}/github/saic-mdal/lama/blob/master/colab/LaMa_inpainting.ipynb/",
        "update": 1676462581
    },
    {
        "name": "SOAT",
        "description": "StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN",
        "author": [
            [
                "Min Jin Chong",
                "https://mchong6.github.io/"
            ],
            [
                "Hsin-Ying Lee",
                "http://hsinyinglee.com/"
            ],
            [
                "David Forsyth",
                "http://luthuli.cs.uiuc.edu/~daf/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mchong6/SOAT",
                369
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.01619"
            ],
            [
                "git",
                "https://github.com/justinpinkney/toonify"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/akhaliq/SOAT"
            ]
        ],
        "tir_url": "{tir_base_url}/github/mchong6/SOAT/blob/master/infinity.ipynb/",
        "update": 1636814284
    },
    {
        "name": "JoJoGAN",
        "description": "One Shot Face Stylization",
        "author": [
            [
                "Min Jin Chong",
                "https://mchong6.github.io/"
            ],
            [
                "David Forsyth",
                "http://luthuli.cs.uiuc.edu/~daf/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mchong6/JoJoGAN",
                1322
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.11641"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/replicate/cog"
            ]
        ],
        "tir_url": "{tir_base_url}/github/mchong6/JoJoGAN/blob/master/stylize.ipynb/",
        "update": 1643834980
    },
    {
        "name": "GANs N' Roses",
        "description": "Stable, Controllable, Diverse Image to Image Translation",
        "author": [
            [
                "Min Jin Chong",
                "https://mchong6.github.io/"
            ],
            [
                "David Forsyth",
                "http://luthuli.cs.uiuc.edu/~daf/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mchong6/GANsNRoses",
                1140
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/znxlwm/UGATIT-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.06561"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.06600"
            ],
            [
                "youtube",
                "https://youtu.be/VNg0NyCGl_4"
            ]
        ],
        "tir_url": "{tir_base_url}/github/mchong6/GANsNRoses/blob/master/inference_colab.ipynb/",
        "update": 1624112482
    },
    {
        "name": "XLS-R",
        "description": "Self-supervised Cross-lingual Speech Representation Learning at Scale",
        "author": [
            [
                "Arun Babu",
                "https://github.com/arbabu123"
            ],
            [
                "Changhan Wang",
                "https://www.changhan.me/"
            ],
            [
                "Andros Tjandra",
                "https://github.com/androstj"
            ],
            [
                "Kushal Lakhotia",
                "https://about.me/hikushalhere"
            ],
            [
                "Qiantong Xu",
                "https://github.com/xuqiantong"
            ],
            [
                "Naman Goyal",
                "https://github.com/ngoyal2707"
            ],
            [
                "Kritika Singh",
                "https://scholar.google.com/citations?user=Ltk3SykAAAAJ"
            ],
            [
                "Patrick von Platen",
                "https://github.com/patrickvonplaten"
            ],
            [
                "Yatharth Saraf",
                "https://scholar.google.com/citations?user=KJTtNJwAAAAJ"
            ],
            [
                "Juan Pino",
                "https://scholar.google.com/citations?user=weU_-4IAAAAJ"
            ],
            [
                "Alexei Baevski",
                "https://github.com/alexeib"
            ],
            [
                "Alexis Conneau",
                "https://github.com/aconneau"
            ],
            [
                "Michael Auli",
                "https://github.com/michaelauli"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2111.09296"
            ],
            [
                "blog post",
                "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2"
            ],
            [
                "git",
                "https://github.com/pytorch/fairseq/blob/main/examples/wav2vec/xlsr/README.md",
                25942
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairscale"
            ]
        ],
        "tir_url": "{tir_base_url}/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_XLS_R_on_Common_Voice.ipynb/",
        "update": 1652167402
    },
    {
        "name": "Disco Diffusion",
        "description": "A frankensteinian amalgamation of notebooks, models and techniques for the generation of AI Art and Animations",
        "author": [
            [
                "Max Ingham",
                "https://github.com/somnai-dreams"
            ],
            [
                "Adam Letts",
                "https://linktr.ee/gandamu"
            ],
            [
                "Daniel Russell",
                "https://github.com/russelldc"
            ],
            [
                "Chigozie Nri",
                "https://github.com/chigozienri"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/alembics/disco-diffusion",
                7222
            ],
            [
                "git",
                "https://github.com/openai/guided-diffusion"
            ],
            [
                "youtube",
                "https://youtu.be/_DtWfh9oS54"
            ],
            [
                "youtube",
                "https://youtu.be/gWxmtdZL8FE"
            ],
            [
                "youtube",
                "https://youtu.be/yVJB6oD0_gM"
            ]
        ],
        "tir_url": "{tir_base_url}/github/alembics/disco-diffusion/blob/main/Disco_Diffusion.ipynb/",
        "update": 1676112817
    },
    {
        "name": "Text2Mesh",
        "description": "Text-Driven Neural Stylization for Meshes",
        "author": [
            [
                "Oscar Michel",
                "https://ojmichel.github.io/"
            ],
            [
                "Roi Bar-On",
                "https://github.com/roibaron"
            ],
            [
                "Richard Liu",
                "https://github.com/factoryofthesun"
            ],
            [
                "Sagie Benaim",
                "https://sagiebenaim.github.io/"
            ],
            [
                "Rana Hanocka",
                "http://people.cs.uchicago.edu/~ranahanocka/"
            ]
        ],
        "links": [
            [
                "project",
                "https://threedle.github.io/text2mesh/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.03221"
            ],
            [
                "CLIP",
                "https://openai.com/blog/clip/"
            ],
            [
                "git",
                "https://github.com/threedle/text2mesh",
                806
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/neverix/text2mesh/notebook"
            ]
        ],
        "tir_url": "{tir_base_url}/github/threedle/text2mesh/blob/master/colab_demo.ipynb/",
        "update": 1652533040
    },
    {
        "name": "GPEN",
        "description": "GAN Prior Embedded Network for Blind Face Restoration in the Wild",
        "author": [
            [
                "Tao Yang",
                "https://cg.cs.tsinghua.edu.cn/people/~tyang/"
            ],
            [
                "Peiran Ren",
                "https://scholar.google.com/citations?&user=x5dEuxsAAAAJ"
            ],
            [
                "Xuansong Xie",
                "https://scholar.google.com/citations?user=M0Ei1zkAAAAJ"
            ],
            [
                "Lei Zhang",
                "http://www4.comp.polyu.edu.hk/~cslzhang/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/yangxy/GPEN",
                1965
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.06070"
            ],
            [
                "demo",
                "https://vision.aliyun.com/experience/detail?spm=a211p3.14020179.J_7524944390.17.66cd4850wVDkUQ&tagName=facebody&children=EnhanceFace"
            ],
            [
                "git",
                "https://github.com/biubug6/Pytorch_Retinaface"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yangxy/GPEN/blob/main/GPEN.ipynb/",
        "update": 1676427643
    },
    {
        "name": "Pose with Style",
        "description": "Detail-Preserving Pose-Guided Image Synthesis with Conditional StyleGAN",
        "author": [
            [
                "Badour AlBahar",
                "https://badouralbahar.github.io/"
            ],
            [
                "Jingwan Lu",
                "https://research.adobe.com/person/jingwan-lu/"
            ],
            [
                "Jimei Yang",
                "https://github.com/jimeiyang"
            ],
            [
                "Zhixin Shu",
                "https://zhixinshu.github.io/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Jia-Bin Huang",
                "https://jbhuang0604.github.io/"
            ]
        ],
        "links": [
            [
                "project",
                "https://pose-with-style.github.io/"
            ],
            [
                "youtube",
                "https://youtu.be/d_ETeAVLilw"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.06166"
            ],
            [
                "git",
                "https://github.com/BadourAlBahar/pose-with-style",
                233
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tg-bomze/collection-of-notebooks/blob/master/HomeStylist.ipynb/",
        "update": 1642603444
    },
    {
        "name": "CLIPasso",
        "description": "Semantically-Aware Object Sketching",
        "author": [
            [
                "Yael Vinker",
                "https://yaelvi116.wixsite.com/mysite"
            ],
            [
                "Ehsan Pajouheshgar",
                "https://pajouheshgar.github.io/"
            ],
            [
                "Jessica Y. Bo",
                "https://jessica-bo.github.io/"
            ],
            [
                "Roman Bachmann",
                "https://roman-bachmann.github.io/"
            ],
            [
                "Amit Bermano",
                "https://www.cs.tau.ac.il/~amberman/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ],
            [
                "Amir Zamir",
                "https://vilab.epfl.ch/zamir/"
            ],
            [
                "Ariel Shamir",
                "https://faculty.runi.ac.il/arik/site/index.asp"
            ]
        ],
        "links": [
            [
                "project",
                "https://clipasso.github.io/clipasso/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.05822"
            ],
            [
                "demo",
                "https://replicate.com/yael-vinker/clipasso"
            ],
            [
                "git",
                "https://github.com/yael-vinker/CLIPasso",
                671
            ],
            [
                "git",
                "https://github.com/BachiLi/diffvg"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.14843"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yael-vinker/CLIPasso/blob/main/CLIPasso.ipynb/",
        "update": 1647870924
    },
    {
        "name": "Score SDE",
        "description": "Score-Based Generative Modeling through Stochastic Differential Equations",
        "author": [
            [
                "Yang Song",
                "https://yang-song.net/"
            ],
            [
                "Jascha Sohl-Dickstein",
                "http://www.sohldickstein.com/"
            ],
            [
                "Diederik Kingma",
                "http://dpkingma.com/"
            ],
            [
                "Abhishek Kumar",
                "https://abhishek.umiacs.io/"
            ],
            [
                "Stefano Ermon",
                "https://cs.stanford.edu/~ermon/"
            ],
            [
                "Ben Poole",
                "https://cs.stanford.edu/~poole/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/yang-song/score_sde",
                978
            ],
            [
                "git",
                "https://github.com/yang-song/score_sde_pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.13456"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.05600"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.09011"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11239"
            ],
            [
                "git",
                "https://github.com/google/ml_collections"
            ],
            [
                "youtube",
                "https://youtu.be/L9ZegT87QK8"
            ]
        ],
        "tir_url": "{tir_base_url}/github/yang-song/score_sde/blob/main/Score_SDE_demo.ipynb/",
        "update": 1616094069
    },
    {
        "name": "Fourier Feature Networks",
        "description": "Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains",
        "author": [
            [
                "Matthew Tancik",
                "https://www.matthewtancik.com/"
            ],
            [
                "Pratul Srinivasan",
                "https://pratulsrinivasan.github.io/"
            ],
            [
                "Ben Mildenhall",
                "https://bmild.github.io/"
            ],
            [
                "Sara Fridovich-Keil",
                "https://people.eecs.berkeley.edu/~sfk/"
            ],
            [
                "Nithin Raghavan",
                "https://cseweb.ucsd.edu//~n2raghavan/"
            ],
            [
                "Utkarsh Singhal",
                "https://scholar.google.com/citations?user=lvA86MYAAAAJ"
            ],
            [
                "Ravi Ramamoorthi",
                "https://cseweb.ucsd.edu//~ravir/"
            ],
            [
                "Jon Barron",
                "https://jonbarron.info/"
            ],
            [
                "Ren Ng",
                "https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html"
            ]
        ],
        "links": [
            [
                "project",
                "https://bmild.github.io/fourfeat/"
            ],
            [
                "neurips",
                "https://proceedings.neurips.cc/paper/2020/hash/55053683268957697aa39fba6f231c68-Abstract.html"
            ],
            [
                "youtube",
                "https://youtu.be/nVA6K6Sn2S4"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1806.07572"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2007/hash/013a006f03dbc5392effeb8f18fda755-Abstract.html"
            ],
            [
                "git",
                "https://github.com/tancik/fourier-feature-networks",
                1018
            ]
        ],
        "tir_url": "{tir_base_url}/github/tancik/fourier-feature-networks/blob/master/Demo.ipynb/",
        "update": 1673981469
    },
    {
        "name": "Global Flow Local Attention",
        "description": "Differentiable global-flow local-attention framework to reassemble the inputs at the feature level",
        "author": [
            [
                "Yurui Ren",
                "https://renyurui.github.io/"
            ],
            [
                "Xiaoming Yu",
                "https://xiaoming-yu.github.io/"
            ],
            [
                "Junming Chen",
                "https://github.com/R-JunmingChen"
            ],
            [
                "Thomas Li",
                "https://ieeexplore.ieee.org/author/37086497292"
            ],
            [
                "Ge Li",
                "https://ieeexplore.ieee.org/author/37085815762"
            ]
        ],
        "links": [
            [
                "project",
                "https://renyurui.github.io/GFLA-web/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.00696"
            ],
            [
                "git",
                "https://github.com/RenYurui/Global-Flow-Local-Attention",
                513
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1605.03557"
            ],
            [
                "medium",
                "https://gt3rs.medium.com/compile-with-nvcc-3566fbdfdbf"
            ],
            [
                "youtube",
                "https://youtu.be/Ju0hBzCwsyU"
            ],
            [
                "git",
                "https://github.com/ondyari/FaceForensics"
            ],
            [
                "data",
                "https://shapenet.org/"
            ],
            [
                "git",
                "https://github.com/NVIDIA/vid2vid"
            ],
            [
                "git",
                "https://github.com/tengteng95/Pose-Transfer"
            ]
        ],
        "tir_url": "{tir_base_url}/github/RenYurui/Global-Flow-Local-Attention/blob/master/demo.ipynb/",
        "update": 1588257621
    },
    {
        "name": "PoolFormer",
        "description": "MetaFormer Is Actually What You Need for Vision",
        "author": [
            [
                "Weihao Yu",
                "https://whyu.me/"
            ],
            [
                "Mi Luo",
                "https://luomi97.github.io/"
            ],
            [
                "Pan Zhou",
                "https://panzhous.github.io/"
            ],
            [
                "Chenyang Si",
                "https://github.com/ChenyangSi"
            ],
            [
                "Yichen Zhou",
                "https://dblp.org/pid/55/10422.html"
            ],
            [
                "Xinchao Wang",
                "https://sites.google.com/site/sitexinchaowang/"
            ],
            [
                "Jiashi Feng",
                "https://sites.google.com/site/jshfeng/"
            ],
            [
                "Shuicheng Yan",
                "https://yanshuicheng.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/sail-sg/poolformer",
                1123
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.11418"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/akhaliq/poolformer"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fvcore"
            ],
            [
                "git",
                "https://github.com/NVIDIA/apex"
            ]
        ],
        "tir_url": "{tir_base_url}/github/sail-sg/poolformer/blob/main/misc/poolformer_demo.ipynb/",
        "update": 1638731538
    },
    {
        "name": "PTI",
        "description": "Pivotal Tuning Inversion enables employing off-the-shelf latent based semantic editing techniques on real images using StyleGAN",
        "author": [
            [
                "Daniel Roich",
                "https://github.com/danielroich"
            ],
            [
                "Ron Mokady",
                "https://rmokady.github.io/"
            ],
            [
                "Amit Bermano",
                "https://www.cs.tau.ac.il/~amberman/"
            ],
            [
                "Daniel Cohen-Or",
                "https://danielcohenor.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/danielroich/PTI",
                585
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.05744"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2-ada-pytorch"
            ],
            [
                "git",
                "https://github.com/richzhang/PerceptualSimilarity"
            ]
        ],
        "tir_url": "{tir_base_url}/github/danielroich/PTI/blob/main/notebooks/inference_playground.ipynb/",
        "update": 1625115931
    },
    {
        "name": "Panini-Net",
        "description": "GAN Prior based Degradation-Aware Feature Interpolation for Face Restoration",
        "author": [
            [
                "Yinhuai Wang",
                "https://github.com/wyhuai"
            ],
            [
                "Yujie Hu",
                "https://villa.jianzhang.tech/people/yujie-hu/"
            ],
            [
                "Jian Zhang",
                "http://jianzhang.tech/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jianzhangcs/panini",
                95
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.08444"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/tkarras/progressive_growing_of_gans"
            ]
        ],
        "tir_url": "{tir_base_url}/github/GeeveGeorge/Panini-Net-Colab/blob/main/PaniniNet_Working.ipynb/",
        "update": 1649814569
    },
    {
        "name": "ConvMixer",
        "description": "An extremely simple model that is similar in spirit to the ViT and the even-more-basic MLP-Mixer in that it operates directly on patches as input, separates the mixing of spatial and channel dimensions, and maintains equal size and resolution throughout the network",
        "author": [
            [
                "Asher Trockman",
                "http://ashertrockman.com/"
            ],
            [
                "Zico Kolter",
                "http://zicokolter.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/locuslab/convmixer",
                1004
            ],
            [
                "git",
                "https://github.com/locuslab/convmixer-cifar10"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.09792"
            ],
            [
                "medium",
                "https://medium.com/codex/an-overview-on-convmixer-patches-are-all-you-need-8502a8d87011"
            ],
            [
                "youtube",
                "https://youtu.be/Gl0s0GDqN3c?t=990"
            ]
        ],
        "tir_url": "{tir_base_url}/github/locuslab/convmixer/blob/main/pytorch-image-models/notebooks/EffResNetComparison.ipynb/",
        "update": 1633466010
    },
    {
        "name": "UniFormer",
        "description": "Unified Transformer for Efficient Spatiotemporal Representation Learning",
        "author": [
            [
                "Kunchang Li",
                "https://github.com/Andy1621"
            ],
            [
                "Yali Wang",
                "https://scholar.google.com/citations?user=hD948dkAAAAJ"
            ],
            [
                "Peng Gao",
                "https://gaopengcuhk.github.io/"
            ],
            [
                "Guanglu Song",
                "https://songguanglu.github.io/"
            ],
            [
                "Yu Liu",
                "https://liuyu.us/"
            ],
            [
                "Hongsheng Li",
                "http://www.ee.cuhk.edu.hk/~hsli/"
            ],
            [
                "Yu Qiao",
                "http://mmlab.siat.ac.cn/yuqiao/index.html"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Sense-X/UniFormer",
                642
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.04676"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.09450"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.10858"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17239"
            ],
            [
                "git",
                "https://github.com/zihangJiang/TokenLabeling"
            ],
            [
                "git",
                "https://github.com/facebookresearch/deit"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fvcore"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models"
            ],
            [
                "git",
                "https://github.com/facebookincubator/submitit"
            ],
            [
                "git",
                "https://github.com/facebookresearch/SlowFast"
            ],
            [
                "git",
                "https://github.com/SwinTransformer/Swin-Transformer-Object-Detection"
            ],
            [
                "git",
                "https://github.com/whai362/PVT/tree/v2/segmentation"
            ],
            [
                "git",
                "https://github.com/HRNet/HRFormer/tree/main/pose"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/Sense-X/uniformer_image_demo"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/Sense-X/uniformer_video_demo"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/Andy1621/uniformer_image_detection"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/Andy1621/uniformer_image_segmentation"
            ]
        ],
        "tir_url": "{tir_base_url}/github/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb/",
        "update": 1680243990
    },
    {
        "name": "EPro-PnP",
        "description": "Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation",
        "author": [
            [
                "Hansheng Chen",
                "https://lakonik.github.io/"
            ],
            [
                "Pichao Wang",
                "https://wangpichao.github.io/"
            ],
            [
                "Fan Wang",
                "https://scholar.google.com/citations?user=WCRGTHsAAAAJ"
            ],
            [
                "Wei Tian",
                "https://scholar.google.com/citations?user=aYKQn88AAAAJ"
            ],
            [
                "Lu Xiong",
                "https://ieeexplore.ieee.org/author/37401835800"
            ],
            [
                "Hao Li",
                "https://scholar.google.com/citations?user=pHN-QIwAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tjiiv-cprg/EPro-PnP",
                914
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.13254"
            ],
            [
                "youtube",
                "https://youtu.be/TonBodQ6EUU"
            ],
            [
                "nuScenes",
                "https://www.nuscenes.org/object-detection?externalData=no&mapData=no&modalities=Camera"
            ],
            [
                "git",
                "https://github.com/megvii-research/petr"
            ],
            [
                "git",
                "https://github.com/HuangJunJie2017/BEVDet"
            ],
            [
                "git",
                "https://github.com/fudan-zvg/PolarFormer"
            ],
            [
                "git",
                "https://github.com/zhiqi-li/BEVFormer"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmdetection3d"
            ]
        ],
        "tir_url": "{tir_base_url}/github/tjiiv-cprg/EPro-PnP/blob/main/demo/fit_identity.ipynb/",
        "update": 1657623752
    },
    {
        "name": "StyleSDF",
        "description": "A high resolution, 3D-consistent image and shape generation technique",
        "author": [
            [
                "Roy Or-El",
                "https://homes.cs.washington.edu/~royorel/"
            ],
            [
                "Xuan Luo",
                "https://roxanneluo.github.io/"
            ],
            [
                "Mengyi Shan",
                "https://shanmy.github.io/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Jeong Joon Park",
                "https://jjparkcv.github.io/"
            ],
            [
                "Ira Kemelmacher-Shlizerman",
                "https://www.irakemelmacher.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://stylesdf.github.io/"
            ],
            [
                "huggingface",
                "https://huggingface.co/spaces/SerdarHelli/StyleSDF-3D"
            ],
            [
                "git",
                "https://github.com/royorel/StyleSDF",
                488
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.11427"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/yenchenlin/nerf-pytorch"
            ]
        ],
        "tir_url": "{tir_base_url}/github/royorel/StyleSDF/blob/main/StyleSDF_demo.ipynb/",
        "update": 1646439925
    },
    {
        "name": "HRFAE",
        "description": "An encoder-decoder architecture for face age editing",
        "author": [
            [
                "Xu Yao",
                "https://xu-yao.github.io/"
            ],
            [
                "Gilles Puy",
                "https://sites.google.com/site/puygilles/home"
            ],
            [
                "Alasdair Newson",
                "https://sites.google.com/site/alasdairnewson/"
            ],
            [
                "Yann Gousseau",
                "https://gousseau.wp.imt.fr/"
            ],
            [
                "Pierre Hellier",
                "https://scholar.google.com/citations?user=U2BX6Q8AAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/InterDigitalInc/HRFAE",
                258
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.04410"
            ],
            [
                "data",
                "https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/"
            ],
            [
                "git",
                "https://github.com/vadimkantorov/caffemodel2pytorch"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ]
        ],
        "tir_url": "{tir_base_url}/github/InterDigitalInc/HRFAE/blob/master/test.ipynb/",
        "update": 1589445187
    },
    {
        "name": "IDE-3D",
        "description": "Interactive Disentangled Editing for High-Resolution 3D-aware Portrait Synthesis",
        "author": [
            [
                "Jingxiang Sun",
                "https://mrtornado24.github.io/"
            ],
            [
                "Xuan Wang",
                "https://xuanwangvc.github.io/"
            ],
            [
                "Yichun Shi",
                "https://seasonsh.github.io/"
            ],
            [
                "Lizhen Wang",
                "https://lizhenwangt.github.io/"
            ],
            [
                "Jue Wang",
                "https://juewang725.github.io/"
            ],
            [
                "Yebin Liu",
                "http://www.liuyebin.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/MrTornado24/IDE-3D",
                417
            ],
            [
                "git",
                "https://arxiv.org/abs/2205.15517"
            ],
            [
                "git",
                "https://github.com/NVlabs/eg3d"
            ],
            [
                "git",
                "https://github.com/NVlabs/ffhq-dataset"
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan3"
            ],
            [
                "youtube",
                "https://youtu.be/Kj5XY_J2Alk"
            ]
        ],
        "tir_url": "{tir_base_url}/github/MrTornado24/IDE-3D/blob/main/inversion/notebooks/inference_playground.ipynb/",
        "update": 1662650457
    },
    {
        "name": "AudioLDM",
        "description": "Text-to-audio system that is built on a latent space to learn the continuous audio representations from contrastive language-audio pretraining latents",
        "author": [
            [
                "Haohe Liu",
                "https://haoheliu.github.io/"
            ],
            [
                "Zehua Chen",
                "https://github.com/zehuachenImperial"
            ],
            [
                "Yi Yuan",
                "https://www.surrey.ac.uk/people/yi-yuan"
            ],
            [
                "Xinhao Mei",
                "https://xinhaomei.github.io/"
            ],
            [
                "Xubo Liu",
                "https://liuxubo717.github.io/"
            ],
            [
                "Danilo Mandic",
                "https://www.imperial.ac.uk/people/d.mandic"
            ],
            [
                "Wenwu Wang",
                "http://personal.ee.surrey.ac.uk/Personal/W.Wang/"
            ],
            [
                "Mark Plumbley",
                "https://www.surrey.ac.uk/people/mark-plumbley"
            ]
        ],
        "links": [
            [
                "project",
                "https://audioldm.github.io/"
            ],
            [
                "git",
                "https://github.com/haoheliu/AudioLDM",
                1590
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2301.12503"
            ],
            [
                "git",
                "https://github.com/LAION-AI/CLAP"
            ],
            [
                "git",
                "https://github.com/CompVis/stable-diffusion"
            ],
            [
                "git",
                "https://github.com/toshas/torch-fidelity"
            ],
            [
                "youtube",
                "https://youtu.be/_0VTltNYhao"
            ]
        ],
        "tir_url": "{tir_base_url}/github/olaviinha/NeuralTextToAudio/blob/main/AudioLDM_pub.ipynb/",
        "update": 1685555644
    },
    {
        "name": "ViDT+",
        "description": "An Extendable, Efficient and Effective Transformer-based Object Detector",
        "author": [
            [
                "Hwanjun Song",
                "https://songhwanjun.github.io/"
            ],
            [
                "Deqing Sun",
                "https://deqings.github.io/"
            ],
            [
                "Sanghyuk Chun",
                "https://sanghyukchun.github.io/home/"
            ],
            [
                "Varun Jampani",
                "https://varunjampani.github.io/"
            ],
            [
                "Dongyoon Han",
                "https://sites.google.com/site/dyhan0920/"
            ],
            [
                "Byeongho Heo",
                "https://sites.google.com/view/byeongho-heo/home"
            ],
            [
                "Wonjae Kim",
                "https://wonjae.kim/"
            ],
            [
                "Ming-Hsuan Yang",
                "http://faculty.ucmerced.edu/mhyang/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/naver-ai/vidt/tree/vidt-plus",
                278
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.07962"
            ],
            [
                "git",
                "https://github.com/fundamentalvision/Deformable-DETR"
            ],
            [
                "git",
                "https://github.com/EherSenaw/ViDT_colab"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2110.03921"
            ]
        ],
        "tir_url": "{tir_base_url}/github/EherSenaw/ViDT_colab/blob/main/vidt_colab.ipynb/",
        "update": 1650432362
    },
    {
        "name": "DiffCSE",
        "description": "Unsupervised contrastive learning framework for learning sentence embeddings",
        "author": [
            [
                "Yung-Sung Chuang",
                "https://people.csail.mit.edu/yungsung/"
            ],
            [
                "Rumen Dangovski",
                "http://super-ms.mit.edu/rumen.html"
            ],
            [
                "Hongyin Luo",
                "https://luohongyin.github.io/"
            ],
            [
                "Yang Zhang",
                "https://mitibmwatsonailab.mit.edu/people/yang-zhang/"
            ],
            [
                "Shiyu Chang",
                "https://code-terminator.github.io/"
            ],
            [
                "Marin Soljačić",
                "http://www.mit.edu/~soljacic/marin.html"
            ],
            [
                "Shang-Wen Li",
                "https://swdanielli.github.io/"
            ],
            [
                "Scott Wen-tau Yih",
                "https://scottyih.org/"
            ],
            [
                "Yoon Kim",
                "https://people.csail.mit.edu/yoonkim/"
            ],
            [
                "James Glass",
                "http://groups.csail.mit.edu/sls/people/glass.shtml"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/voidism/diffcse",
                250
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.10298"
            ],
            [
                "huggingface",
                "https://huggingface.co/voidism"
            ],
            [
                "twitter",
                "https://twitter.com/YungSungChuang/status/1517518077902000129"
            ],
            [
                "git",
                "https://github.com/princeton-nlp/SimCSE"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.08821"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.00899"
            ]
        ],
        "tir_url": "{tir_base_url}/github/voidism/DiffCSE/blob/master/diffcse_evaluation.ipynb/",
        "update": 1650755146
    },
    {
        "name": "EVA3D",
        "description": "High-quality unconditional 3D human generative model that only requires 2D image collections for training",
        "author": [
            [
                "Fangzhou Hong",
                "https://hongfz16.github.io/"
            ],
            [
                "Zhaoxi Chen",
                "https://frozenburning.github.io/"
            ],
            [
                "Yushi Lan",
                "https://github.com/NIRVANALAN"
            ],
            [
                "Liang Pan",
                "https://github.com/paul007pl"
            ],
            [
                "Ziwei Liu",
                "https://liuziwei7.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/hongfz16/EVA3D",
                431
            ],
            [
                "project",
                "https://hongfz16.github.io/projects/EVA3D.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2210.04888"
            ],
            [
                "youtube",
                "https://youtu.be/JNV0FJ0aDWM"
            ],
            [
                "youtube",
                "https://youtu.be/M-kyvzTQrBI"
            ]
        ],
        "tir_url": "{tir_base_url}/github/hongfz16/EVA3D/blob/main/notebook/EVA3D_Demo.ipynb/",
        "update": 1680776511
    },
    {
        "name": "SwinIR",
        "description": "Image Restoration Using Swin Transformer",
        "author": [
            [
                "Jingyun Liang",
                "https://jingyunliang.github.io/"
            ],
            [
                "Jiezhang Cao",
                "https://github.com/caojiezhang"
            ],
            [
                "Guolei Sun",
                "https://github.com/GuoleiSun"
            ],
            [
                "Kai Zhang",
                "https://cszn.github.io/"
            ],
            [
                "Luc Van Gool",
                "https://scholar.google.com/citations?user=TwMib_QAAAAJ"
            ],
            [
                "Radu Timofte",
                "https://www.informatik.uni-wuerzburg.de/computervision/home/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2108.10257"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.10833"
            ],
            [
                "git",
                "https://github.com/JingyunLiang/SwinIR",
                3187
            ],
            [
                "git",
                "https://github.com/cszn/BSRGAN"
            ],
            [
                "git",
                "https://github.com/microsoft/Swin-Transformer"
            ],
            [
                "git",
                "https://github.com/cszn/KAIR"
            ]
        ],
        "tir_url": "{tir_base_url}/gist/JingyunLiang/a5e3e54bc9ef8d7bf594f6fee8208533/swinir-demo-on-real-world-image-sr.ipynb/",
        "update": 1655488306
    },
    {
        "name": "VRT",
        "description": "A Video Restoration Transformer",
        "author": [
            [
                "Jingyun Liang",
                "https://jingyunliang.github.io/"
            ],
            [
                "Jiezhang Cao",
                "https://github.com/caojiezhang"
            ],
            [
                "Yuchen Fan",
                "https://ychfan.github.io/"
            ],
            [
                "Kai Zhang",
                "https://cszn.github.io/"
            ],
            [
                "Yawei Li",
                "https://ofsoundof.github.io/"
            ],
            [
                "Radu Timofte",
                "https://www.informatik.uni-wuerzburg.de/computervision/home/"
            ],
            [
                "Luc Van Gool",
                "https://scholar.google.com/citations?user=TwMib_QAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/JingyunLiang/VRT",
                981
            ],
            [
                "git",
                "https://github.com/cszn/KAIR"
            ],
            [
                "git",
                "https://github.com/SwinTransformer/Video-Swin-Transformer"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmediting"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.12288"
            ]
        ],
        "tir_url": "{tir_base_url}/gist/JingyunLiang/deb335792768ad9eb73854a8efca4fe0/vrt-demo-on-video-restoration.ipynb/",
        "update": 1655307791
    },
    {
        "name": "Deep Painterly Harmonization",
        "description": "Algorithm produces significantly better results than photo compositing or global stylization techniques and that it enables creative painterly edits that would be otherwise difficult to achieve",
        "author": [
            [
                "Fujun Luan",
                "https://luanfujun.github.io/"
            ],
            [
                "Sylvain Paris",
                "http://people.csail.mit.edu/sparis/"
            ],
            [
                "Eli Shechtman",
                "https://research.adobe.com/person/eli-shechtman/"
            ],
            [
                "Kavita Bala",
                "https://www.cs.cornell.edu/~kb/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/luanfujun/deep-painterly-harmonization",
                6105
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1804.03189"
            ],
            [
                "git",
                "https://github.com/jcjohnson/neural-style"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1701.08893"
            ],
            [
                "git",
                "https://github.com/torch/torch7"
            ],
            [
                "git",
                "https://github.com/szagoruyko/loadcaffe"
            ]
        ],
        "tir_url": "{tir_base_url}/gist/eyaler/5303782669fb43510d398bd346c6e3e6/deep-painterly-harmonization.ipynb/",
        "update": 1649335024
    }
]